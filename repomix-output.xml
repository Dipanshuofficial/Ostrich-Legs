This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitignore
Architecture.md
client/.gitignore
client/eslint.config.js
client/index.html
client/package.json
client/README.md
client/src/App.tsx
client/src/components/Card.tsx
client/src/core/theme.css
client/src/core/types.ts
client/src/features/connection/DeviceConnector.tsx
client/src/features/dashboard/ActiveSwarm.tsx
client/src/features/dashboard/ComputeActivity.tsx
client/src/features/dashboard/JobGauge.tsx
client/src/features/dashboard/OptimizationInsights.tsx
client/src/features/dashboard/ResourceStats.tsx
client/src/features/dashboard/SwarmControls.tsx
client/src/features/dashboard/ThrottleControl.tsx
client/src/features/dashboard/VelocityMonitor.tsx
client/src/features/terminal/LiveTerminal.tsx
client/src/hooks/useComputeSwarm.ts
client/src/hooks/useSwarmEngine.ts
client/src/hooks/useSwarmExecution.ts
client/src/main.tsx
client/src/utils/compute.worker.ts
client/src/utils/worker.ts
client/tsconfig.app.json
client/tsconfig.json
client/tsconfig.node.json
client/vite.config.ts
Resource_share-COLAB.ipynb
server/package.json
server/src/core/types.ts
server/src/index.ts
server/src/managers/DeviceManager.ts
server/src/managers/JobScheduler.ts
server/tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitignore">
node_modules/

# Markdowns for notes
AGENTS.md
PROJECT_CONTEXT.md

# Repomix
repomix.config.json
repomix-output.xml

# Images
flowchartinsp.png
</file>

<file path="Architecture.md">
Client Architecture Plan: Ostrich-Legs
Resource Impact Analysis & CPU Usage Investigation

---

1. EXECUTIVE SUMMARY
   

---

2. COMPLETE FILE ARCHITECTURE
   D:\JOB\Ostrich-Legs\client\
   â”œâ”€â”€ Configuration Layer
   â”‚ â”œâ”€â”€ vite.config.ts # Build tool configuration
   â”‚ â”œâ”€â”€ tsconfig\*.json # TypeScript configurations (3 files)
   â”‚ â”œâ”€â”€ eslint.config.js # Linting rules
   â”‚ â””â”€â”€ package.json # Dependencies & scripts
   â”‚
   â”œâ”€â”€ Entry Points
   â”‚ â”œâ”€â”€ index.html # HTML entry
   â”‚ â”œâ”€â”€ src/main.tsx # React DOM mount
   â”‚ â””â”€â”€ src/App.tsx # Root component
   â”‚
   â”œâ”€â”€ Core Hooks (CPU-Intensive)
   â”‚ â”œâ”€â”€ src/hooks/useComputeSwarm.ts # Main orchestration hook
   â”‚ â””â”€â”€ src/hooks/usePersistentIdentity.ts # Device ID management
   â”‚
   â”œâ”€â”€ Web Workers (Maximum CPU)
   â”‚ â””â”€â”€ src/utils/worker.ts # Worker manager + sub-workers
   â”‚
   â”œâ”€â”€ UI Components
   â”‚ â”œâ”€â”€ src/components/ui/
   â”‚ â”‚ â”œâ”€â”€ Card.tsx # Layout wrapper
   â”‚ â”‚ â”œâ”€â”€ Badge.tsx # Status indicators
   â”‚ â”‚ â””â”€â”€ ThemeToggle.tsx # Dark/light mode
   â”‚ â”‚
   â”‚ â””â”€â”€ src/components/dashboard/
   â”‚ â”œâ”€â”€ GpuStatusMonitor.tsx # Canvas velocity chart [HIGH CPU]
   â”‚ â”œâ”€â”€ SwarmDashboard.tsx # Device list & stats
   â”‚ â”œâ”€â”€ StatusMonitor.tsx # Recharts (unused)
   â”‚ â”œâ”€â”€ LiveTerminal.tsx # Log console
   â”‚ â”œâ”€â”€ DeviceHealth.tsx # Benchmark display
   â”‚ â”œâ”€â”€ ThrottleControl.tsx # CPU slider
   â”‚ â”œâ”€â”€ SwarmControls.tsx # Start/Pause buttons
   â”‚ â””â”€â”€ DeviceConnector.tsx # QR code modal
   â”‚
   â”œâ”€â”€ Styles
   â”‚ â””â”€â”€ src/index.css # Tailwind v4 + custom CSS
   â”‚
   â””â”€â”€ Assets
   â””â”€â”€ src/assets/react.svg # Static asset

---

3. RESOURCE IMPACT BY FILE
   CRITICAL CPU CONSUMERS ðŸ”´
   src/utils/worker.ts - HIGHEST IMPACT
   Resource Profile:

- CPU: 70-100% when active (intentional - this IS the compute engine)
- Memory: 50-200MB depending on thread pool size
- GPU: Uses WebGPU when available (2 billion ops/matrix)
  Architecture:
  Main Thread
  â””â”€â”€ OstrichWorker (Manager)
  â””â”€â”€ Thread Pool (Dynamic 1-N workers)
  â””â”€â”€ Sub-Workers (Created via Blob URLs)
  â”œâ”€â”€ GPU Kernel (WGSL shader)
  â””â”€â”€ CPU Kernel (Math loops)
  Resource Hotspots:

1. Lines 15-38: WGSL shader compilation (one-time, expensive)
2. Lines 41-186: Sub-worker factory - creates workers via new Blob() + URL.createObjectURL()
3. Lines 46-59: CPU stress test - Math.sqrt(i) \* Math.sin(i) in tight loop
4. Lines 85-134: GPU matrix multiplication - 1000Ã—1000 = 2 billion operations
5. Lines 188-241: Dynamic thread pool scaling based on throttleLimit
   Impact Assessment:

- Development Mode: Workers run at full throttle regardless of dev server
- Thread Creation: Each sub-worker is a separate JS context (memory overhead)
- Blob URLs: URL.createObjectURL creates memory pressure if not revoked properly

---

src/hooks/useComputeSwarm.ts - HIGH IMPACT
Resource Profile:

- CPU: 5-15% from intervals and socket handling
- Memory: Low (~5MB)
- Network: Continuous WebSocket traffic
  Critical Sections:
  Lines 101-112: UI Sync Loop
  const uiInterval = setInterval(() => {
  setCompletedCount((prev) => {
  if (prev !== completedCountRef.current) {
  return completedCountRef.current; // State update every 500ms
  }
  return prev;
  });
  }, 500);
- Impact: Forces React re-evaluation every 500ms even if value unchanged
- Optimization: Use requestAnimationFrame instead, or only update on actual change
  Lines 114-131: Auto-Request Loop
  const interval = setInterval(() => {
  if (socketRef.current?.connected) {
  socketRef.current.emit("job:request_batch"); // Every 1000ms when running
  }
  }, 1000);
- Impact: Network overhead + server load
- Note: This is likely the intended behavior for distributed computing
  Lines 30-98: Master Setup Effect
- Creates Web Worker (lines 32-33)
- Socket.io connection with reconnection (lines 62-67)
- Event listeners for: connect, snapshot, join codes, benchmarks, job batches

---

src/components/dashboard/GpuStatusMonitor.tsx - MEDIUM-HIGH IMPACT
Resource Profile:

- CPU: 10-20% from canvas rendering
- GPU: Moderate (2D canvas acceleration)
- Memory: Low (60 data points buffer)
  Critical Sections:
  Lines 66-137: Animation Loop
  const draw = () => {
  // ... canvas drawing logic ...
  animationFrameId = requestAnimationFrame(draw); // 60 FPS continuous
  };
  draw();
- Impact: Runs at 60fps continuously, even when tab not visible
- Drawing Operations:
  - Lines 71: clearRect every frame
  - Lines 79-88: Grid drawing (4 lines)
  - Lines 100-125: Chart with gradients (60 iterations)
  - Lines 128-135: Text rendering
    Lines 54-64: Data Sampling Interval
    const dataInterval = setInterval(() => {
    const delta = countRef.current - prevCountRef.current;
    // ... push new data point every 500ms
    }, 500);
    Canvas Resizing (Lines 47-51):
    const dpr = window.devicePixelRatio || 1;
    canvas.width = rect.width _ dpr; // High-DPI scaling
    canvas.height = rect.height _ dpr;
    ctx.scale(dpr, dpr);
- Impact: Double memory on retina displays

---

MODERATE IMPACT ðŸŸ¡
vite.config.ts - DEV MODE ONLY
Resource Profile:

- CPU: 20-40% during HMR (Hot Module Replacement)
- Memory: 100-300MB for dev server
- Disk: File watching overhead
  Configuration Analysis:
- Line 7: @vitejs/plugin-react-swc - Uses SWC (Rust-based, fast but memory hungry)
- Lines 9-20: Proxy configuration forwards /api and /socket.io to port 3000
- Issue: --host flag exposes to network, increasing overhead
  Why bun run dev is slow:

1. SWC compilation in real-time
2. File system watching with fs.watch
3. Proxy middleware processing
4. Source map generation
5. CSS processing (Tailwind v4)

---

src/App.tsx - MODERATE IMPACT
Resource Profile:

- CPU: 5-10% from re-renders
- Memory: 20-50MB (depends on device list size)
  Optimization Strategies Used (Good):
- Lines 16-21: Memoized components prevent cascading re-renders
- Lines 58-96: useMemo for expensive stats calculation
- Lines 28-30: useCallback for log function
  Potential Issues:
- Lines 44-45: completedCount updates trigger swarmStats recalculation (line 83)
- Lines 142-180: All memoized components still receive new props on every parent render

---

src/components/dashboard/LiveTerminal.tsx - LOW-MODERATE
Resource Profile:

- CPU: 2-5% from scrolling animation
- Memory: Grows with log history (capped at 19 lines)
  Lines 15-19: Scroll Effect
  useEffect(() => {
  if (logsEndRef.current) {
  logsEndRef.current.scrollIntoView({ behavior: "smooth" });
  }
  }, [logs]); // Runs on every new log entry

---

LOW IMPACT ðŸŸ¢
| File | Impact | Notes |
|------|--------|-------|
| main.tsx | Minimal | Simple React mount |
| usePersistentIdentity.ts | Minimal | One-time localStorage read |
| Card.tsx | Minimal | Presentational |
| ThemeToggle.tsx | Minimal | User-triggered only |
| index.css | Low | Some CSS animations (grain effect) |

---

4. CPU USAGE BREAKDOWN (Development Mode)
   When Running bun run dev:
   Total CPU Usage: 40-150% (multi-core)
   Breakdown by Component:
   â”œâ”€â”€ Vite Dev Server 20-40%
   â”‚ â”œâ”€â”€ SWC Compilation 10-20%
   â”‚ â”œâ”€â”€ File Watching 5-10%
   â”‚ â”œâ”€â”€ HMR Processing 5-10%
   â”‚ â””â”€â”€ Proxy Middleware 2-5%
   â”‚
   â”œâ”€â”€ Web Workers 30-100% (INTENTIONAL)
   â”‚ â”œâ”€â”€ Thread Pool 20-80%
   â”‚ â”œâ”€â”€ GPU Compute 0-50% (if WebGPU available)
   â”‚ â””â”€â”€ CPU Math Kernels 10-50%
   â”‚
   â”œâ”€â”€ React/UI 10-25%
   â”‚ â”œâ”€â”€ Canvas Animation 10-20%
   â”‚ â”œâ”€â”€ State Updates 3-8%
   â”‚ â”œâ”€â”€ Socket.io Events 2-5%
   â”‚ â””â”€â”€ Component Rendering 1-3%
   â”‚
   â””â”€â”€ Browser Overhead 5-10%
   â”œâ”€â”€ Garbage Collection 2-5%
   â”œâ”€â”€ DOM Updates 2-4%
   â””â”€â”€ Event Loop 1-2%

---

5. SPECIFIC BOTTLENECKS IDENTIFIED
   Bottleneck 1: Continuous Animation (GpuStatusMonitor.tsx:67)
   const draw = () => {
   // ... draws every frame
   animationFrameId = requestAnimationFrame(draw); // NEVER STOPS
   };
   Issue: Animation runs even when:

- Tab is backgrounded
- Swarm is IDLE
- Window is minimized
  Fix Strategy:
  // Use Page Visibility API
  document.addEventListener('visibilitychange', () => {
  if (document.hidden) {
  cancelAnimationFrame(animationFrameId);
  } else {
  draw();
  }
  });

---

Bottleneck 2: Unnecessary State Sync (useComputeSwarm.ts:101-112)
setInterval(() => {
setCompletedCount((prev) => {
if (prev !== completedCountRef.current) {
return completedCountRef.current;
}
return prev;
});
}, 500);
Issue: Checks state every 500ms even when no jobs complete
Fix Strategy:
// Only update when value actually changes
useEffect(() => {
const checkInterval = setInterval(() => {
if (completedCountRef.current !== lastEmittedRef.current) {
setCompletedCount(completedCountRef.current);
lastEmittedRef.current = completedCountRef.current;
}
}, 500);
}, []);

---

Bottleneck 3: Canvas Full Redraw Every Frame (GpuStatusMonitor.tsx:71-125)
Issue: Redraws entire 60-point chart at 60fps (3600 operations/sec)
Optimization Options:

1. Double Buffering: Draw to offscreen canvas, swap
2. Incremental Drawing: Only draw new data points
3. Reduce FPS: Cap at 30fps for charts (sufficient for data viz)
4. WebGL: For truly high-performance rendering

---

Bottleneck 4: Worker Thread Overhead (worker.ts:41-186)
Issue: Each sub-worker is created via Blob URL
const blob = new Blob([code], { type: "application/javascript" });
const objectUrl = URL.createObjectURL(blob);
return { worker: new Worker(objectUrl), objectUrl };
Memory Impact:

- Each worker context: ~5-10MB
- Thread pool default: LOGICAL_CORES \* 0.3 (e.g., 8 cores = 2-3 workers)
- Total: 15-30MB just for worker overhead

---

Bottleneck 5: Vite SWC in Bun (vite.config.ts:7)
Issue: You're using Bun runtime with SWC (Rust-based) compiler

- SWC is optimized for Node.js
- Bun has its own native bundler that's faster
- Running SWC under Bun adds translation overhead

---

6. OPTIMIZATION RECOMMENDATIONS
   Immediate Wins (Low Effort, High Impact)
1. Pause Canvas When Idle
   - Add visibility checking to GpuStatusMonitor
   - Pause animation when status === 'IDLE'
1. Throttle State Updates
   - Reduce UI sync interval from 500ms to 1000-2000ms
   - Use requestAnimationFrame + timestamp checking
1. Optimize Vite Dev
   - Use bunx --bun vite instead of bun run dev (native Bun compilation)
   - Or switch to npm run dev with Node for SWC optimization
1. Add Worker Throttling
   - Respect throttle setting even in dev mode
   - Add devMode: low-power option
     Medium-Term Improvements
1. Canvas Optimization
   - Implement dirty-rectangle rendering
   - Use will-change: contents CSS hint
   - Consider switching to WebGL for complex charts
1. Web Worker Pool
   - Pre-allocate workers at startup
   - Reuse workers instead of terminating/creating
   - Use SharedArrayBuffer for zero-copy communication
1. React Optimizations
   - Add React.memo to pure components (already partially done)
   - Virtualize device list if >50 devices
   - Use useDeferredValue for non-urgent updates
     Long-Term Architecture
1. Separate Dev/Prod Worker Behavior
   - Workers auto-pause in dev mode when no activity
   - Separate development bundle without heavy compute
1. Replace Canvas with WebGL
   - Use Three.js or raw WebGL for velocity charts
   - GPU-accelerated rendering reduces CPU load
1. Bun-Native Build
   - Create Bun-native worker implementation
   - Use Bun's built-in bundler instead of Vite

---

7. FILE-BY-FILE OPTIMIZATION CHECKLIST
   High Priority

- [ ] GpuStatusMonitor.tsx: Add visibility-aware animation pausing
- [ ] useComputeSwarm.ts: Reduce sync interval, optimize effect deps
- [ ] worker.ts: Add dev-mode throttling, optimize thread pool scaling
      Medium Priority
- [ ] vite.config.ts: Evaluate Bun-native alternatives
- [ ] App.tsx: Add useDeferredValue for stats
- [ ] LiveTerminal.tsx: Virtualize long log lists
      Low Priority
- [ ] index.css: Optimize grain texture (CSS containment)
- [ ] SwarmDashboard.tsx: Virtualize device list
- [ ] ThemeToggle.tsx: Preload theme to avoid flash

---

8. MEASURING IMPROVEMENTS
   Use these Chrome DevTools metrics:
1. Performance Tab: Record 10 seconds of activity
   - Look for long frames (>16ms)
   - Check "Scripting" vs "Rendering" time
1. Memory Tab: Take heap snapshots
   - Monitor Worker-related memory
   - Check for detached DOM nodes
1. Network Tab: Monitor WebSocket traffic
   - Batch job requests should dominate
   - Watch for unnecessary polling
1. Bun Built-in Profiler:
   bun --inspect run dev

---

9. SUMMARY
   Your CPU usage is expected behavior for a distributed computing client that:

- Runs continuous mathematical computations
- Maintains real-time WebSocket connections
- Renders high-frequency data visualizations
- Uses Vite's development server with HMR
  The heavy load is primarily from:

1. Intentional compute work (Web Workers) - 70-100%
2. Vite dev server overhead - 20-40%
3. Canvas animation - 10-20%
   Quick fixes to try immediately:
4. Switch to bunx --bun vite for native Bun performance
5. Add if (status === 'IDLE') return null; to GpuStatusMonitor when not running
6. Reduce setInterval in useComputeSwarm from 500ms to 2000ms
</file>

<file path="client/.gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
</file>

<file path="client/eslint.config.js">
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import tseslint from 'typescript-eslint'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      js.configs.recommended,
      tseslint.configs.recommended,
      reactHooks.configs.flat.recommended,
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
    },
  },
])
</file>

<file path="client/index.html">
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>client</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
</file>

<file path="client/README.md">
# React + TypeScript + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) (or [oxc](https://oxc.rs) when used in [rolldown-vite](https://vite.dev/guide/rolldown)) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## React Compiler

The React Compiler is currently not compatible with SWC. See [this issue](https://github.com/vitejs/vite-plugin-react/issues/428) for tracking the progress.

## Expanding the ESLint configuration

If you are developing a production application, we recommend updating the configuration to enable type-aware lint rules:

```js
export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      // Other configs...

      // Remove tseslint.configs.recommended and replace with this
      tseslint.configs.recommendedTypeChecked,
      // Alternatively, use this for stricter rules
      tseslint.configs.strictTypeChecked,
      // Optionally, add this for stylistic rules
      tseslint.configs.stylisticTypeChecked,

      // Other configs...
    ],
    languageOptions: {
      parserOptions: {
        project: ['./tsconfig.node.json', './tsconfig.app.json'],
        tsconfigRootDir: import.meta.dirname,
      },
      // other options...
    },
  },
])
```

You can also install [eslint-plugin-react-x](https://github.com/Rel1cx/eslint-react/tree/main/packages/plugins/eslint-plugin-react-x) and [eslint-plugin-react-dom](https://github.com/Rel1cx/eslint-react/tree/main/packages/plugins/eslint-plugin-react-dom) for React-specific lint rules:

```js
// eslint.config.js
import reactX from 'eslint-plugin-react-x'
import reactDom from 'eslint-plugin-react-dom'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      // Other configs...
      // Enable lint rules for React
      reactX.configs['recommended-typescript'],
      // Enable lint rules for React DOM
      reactDom.configs.recommended,
    ],
    languageOptions: {
      parserOptions: {
        project: ['./tsconfig.node.json', './tsconfig.app.json'],
        tsconfigRootDir: import.meta.dirname,
      },
      // other options...
    },
  },
])
```
</file>

<file path="client/src/components/Card.tsx">
import { type ReactNode } from "react";
import { clsx, type ClassValue } from "clsx";
import { twMerge } from "tailwind-merge";

function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}

interface CardProps {
  children: ReactNode;
  className?: string;
  variant?: "flat" | "elevated" | "glass";
}

export const Card = ({
  children,
  className,
  variant = "elevated",
}: CardProps) => {
  const variants = {
    flat: "bg-surface-white border border-border-soft",
    elevated: "soft-card",
    glass: "bg-white/70 backdrop-blur-md border border-white/20 shadow-lg",
  };

  return <div className={cn(variants[variant], className)}>{children}</div>;
};
</file>

<file path="client/src/core/theme.css">
@import "tailwindcss";

@theme {
  /* Neuronix Color Palette */
  --color-brand-orange: #ff7d54;
  --color-brand-peach: #ffb09c;
  --color-surface-white: #fcfcfd;
  --color-surface-muted: #f3f4f6;
  --color-text-main: #1a1a1e;
  --color-text-muted: #6b7280;
  --color-border-soft: rgba(0, 0, 0, 0.05);

  /* Elevation (Neumorphism) */
  --shadow-soft-depth:
    0 10px 25px -5px rgba(0, 0, 0, 0.03), 0 8px 10px -6px rgba(0, 0, 0, 0.03);
  --shadow-card: 0 20px 40px -12px rgba(0, 0, 0, 0.05);
  --shadow-inset: inset 0 2px 4px 0 rgba(0, 0, 0, 0.05);

  /* Radii */
  --radius-xl: 24px;
  --radius-2xl: 32px;
}

:root {
  background-color: var(--color-surface-muted);
  color: var(--color-text-main);
  font-family: "Inter", sans-serif;
}

@layer components {
  /* The Neuronix Soft Card */
  .soft-card {
    @apply bg-surface-white border border-border-soft shadow-card rounded-2xl p-6 transition-all;
  }

  /* Modern Scrollbar */
  ::-webkit-scrollbar {
    width: 6px;
  }
  ::-webkit-scrollbar-thumb {
    @apply bg-gray-200 rounded-full hover:bg-gray-300;
  }
}
</file>

<file path="client/src/core/types.ts">
/** * @priority Latest TypeScript Docs
 * Strict Domain Model for Ostrich Swarm
 */

export type SwarmStatus = "IDLE" | "RUNNING" | "PAUSED" | "STOPPED";
export type DeviceType = "DESKTOP" | "MOBILE" | "COLAB" | "SERVER";
export type JobType = "MATH_STRESS" | "MAT_MUL" | "TEXT_TOKENIZE";

export interface DeviceCapabilities {
  cpuCores: number;
  memoryGB: number;
  gpuAvailable: boolean;
  gpuName?: string; // Added for detail
}

export interface DeviceInfo {
  id: string;
  name: string;
  type: DeviceType;
  status: "ONLINE" | "BUSY" | "OFFLINE" | "DISABLED";
  capabilities: DeviceCapabilities;
  opsScore: number;
  totalJobsCompleted: number;
  lastHeartbeat: number;
}

export interface SwarmResources {
  totalCores: number;
  totalMemory: number;
  totalGPUs: number; // Added GPU tracking
  onlineCount: number;
}

export interface SwarmSnapshot {
  runState: "IDLE" | "RUNNING" | "PAUSED" | "STOPPED";
  devices: Record<string, DeviceInfo>;
  stats: {
    totalJobs: number;
    activeJobs: number;
    pendingJobs: number;
    completedJobs: number;
    globalVelocity: number;
  };
  resources: SwarmResources; // <--- The missing property
}
</file>

<file path="client/src/features/connection/DeviceConnector.tsx">
import { QRCodeSVG } from "qrcode.react";
import { X, Copy, Share2 } from "lucide-react";
import { Card } from "../../components/Card";

interface DeviceConnectorProps {
  readonly isOpen: boolean;
  readonly joinCode: string;
  readonly onClose: () => void;
}

export const DeviceConnector = ({
  isOpen,
  joinCode,
  onClose,
}: DeviceConnectorProps) => {
  if (!isOpen) return null;

  const copyCode = () => {
    navigator.clipboard.writeText(joinCode);
  };

  return (
    <div className="fixed inset-0 z-50 flex items-center justify-center bg-gray-900/40 backdrop-blur-md p-6">
      <Card
        className="max-w-sm w-full relative animate-in zoom-in-95 duration-200"
        variant="elevated"
      >
        <button
          onClick={onClose}
          className="absolute top-4 right-4 p-2 hover:bg-gray-100 rounded-full transition-colors"
        >
          <X size={18} className="text-text-muted" />
        </button>

        <div className="text-center space-y-6 py-4">
          <div className="space-y-2">
            <h3 className="text-xl font-bold">Add Compute Node</h3>
            <p className="text-xs text-text-muted">
              Scan to join the distributed swarm
            </p>
          </div>

          <div className="inline-block p-4 bg-white border border-border-soft rounded-3xl shadow-sm">
            <QRCodeSVG
              value={`https://ostrich.legs/join/${joinCode}`}
              size={160}
            />
          </div>

          <div className="space-y-2">
            <p className="text-[10px] font-bold text-text-muted uppercase tracking-widest">
              Manual Join Code
            </p>
            <div className="flex items-center gap-2 bg-gray-100 p-2 rounded-xl border border-border-soft">
              <code className="flex-1 font-mono font-bold text-lg text-brand-orange">
                {joinCode}
              </code>
              <button
                onClick={copyCode}
                className="p-2 hover:bg-white rounded-lg shadow-sm transition-all active:scale-90"
              >
                <Copy size={16} className="text-text-muted" />
              </button>
            </div>
          </div>
        </div>
      </Card>
    </div>
  );
};
</file>

<file path="client/src/features/dashboard/ActiveSwarm.tsx">
import { Smartphone, Laptop, Server, Cpu, Play } from "lucide-react";
import { Card } from "../../components/Card";
import { type DeviceInfo } from "../../core/types";

interface ActiveSwarmProps {
  devices: DeviceInfo[];
  onBenchmark: () => void;
  onToggle: (id: string, state: boolean) => void;
}

export const ActiveSwarm = ({
  devices,
  onBenchmark,
  onToggle,
}: ActiveSwarmProps) => {
  const getIcon = (type: string) => {
    switch (type) {
      case "MOBILE":
        return <Smartphone size={18} />;
      case "SERVER":
        return <Server size={18} />;
      case "COLAB":
        return <Cpu size={18} />;
      default:
        return <Laptop size={18} />;
    }
  };

  return (
    <Card className="flex flex-col h-full bg-surface-white relative overflow-hidden group p-1">
      <div className="flex justify-between items-center mb-6 px-2 pt-2">
        <div>
          <h3 className="font-bold text-lg text-text-main">Swarm Nodes</h3>
          <p className="text-xs text-text-muted">Manage active resources</p>
        </div>
        <button
          onClick={onBenchmark}
          className="flex items-center gap-2 bg-gray-900 hover:bg-black text-white px-4 py-2 rounded-xl text-xs font-bold transition-all active:scale-95 shadow-lg shadow-gray-900/20"
        >
          <Play size={12} fill="currentColor" />
          Benchmark
        </button>
      </div>

      <div className="flex-1 overflow-y-auto space-y-3 custom-scrollbar px-1">
        {devices.map((device) => {
          const isDisabled = device.status === "DISABLED";
          const isLocal = device.name === "Local Host";

          return (
            <div
              key={device.id}
              className={`flex items-center justify-between p-3 rounded-2xl border transition-all duration-300 ${isDisabled ? "bg-gray-50 border-transparent opacity-60" : "bg-white border-gray-100 hover:border-brand-orange/30 shadow-sm"}`}
            >
              <div className="flex items-center gap-3">
                <div
                  className={`p-3 rounded-xl ${isDisabled ? "bg-gray-200 text-gray-400" : "bg-surface-muted text-brand-orange"}`}
                >
                  {getIcon(device.type)}
                </div>
                <div>
                  <div className="flex items-center gap-2">
                    <h4 className="text-sm font-bold text-text-main">
                      {device.name}
                    </h4>
                    {isLocal && (
                      <span className="text-[9px] bg-brand-orange/10 text-brand-orange px-1.5 rounded font-bold border border-brand-orange/20">
                        YOU
                      </span>
                    )}
                  </div>
                  <div className="flex items-center gap-2 mt-0.5">
                    <span
                      className={`w-1.5 h-1.5 rounded-full ${isDisabled ? "bg-gray-400" : device.status === "ONLINE" ? "bg-green-500" : "bg-amber-500"}`}
                    />
                    <span className="text-[10px] font-bold text-text-muted uppercase">
                      {device.status === "ONLINE"
                        ? `${device.capabilities.cpuCores} Cores`
                        : device.status}
                    </span>
                  </div>
                </div>
              </div>

              <div className="flex items-center gap-4">
                {/* Job Counter */}
                <div className="text-right hidden sm:block">
                  <div className="font-mono text-sm font-black text-text-main">
                    {/* Placeholder for Job Count - will connect to real state later */}
                    {device.totalJobsCompleted || 0}
                  </div>
                  <div className="text-[9px] font-bold text-text-muted uppercase">
                    Jobs Done
                  </div>
                </div>

                <div className="text-right hidden sm:block min-w-15">
                  <div className="font-mono text-sm font-black text-brand-orange">
                    {device.opsScore > 0
                      ? device.opsScore.toLocaleString()
                      : "---"}
                  </div>
                  <div className="text-[9px] font-bold text-text-muted uppercase">
                    OPS Score
                  </div>
                </div>

                <button
                  onClick={() => onToggle(device.id, isDisabled)}
                  className={`w-10 h-6 rounded-full p-1 transition-colors relative ${!isDisabled ? "bg-green-500" : "bg-gray-300"}`}
                >
                  <div
                    className={`w-4 h-4 rounded-full bg-white shadow-sm transition-transform duration-200 ${!isDisabled ? "translate-x-4" : "translate-x-0"}`}
                  />
                </button>
              </div>
            </div>
          );
        })}
      </div>
    </Card>
  );
};
</file>

<file path="client/src/features/dashboard/ComputeActivity.tsx">
import {
  BarChart,
  Bar,
  XAxis,
  YAxis,
  ResponsiveContainer,
  Cell,
  Tooltip,
} from "recharts";
import { Card } from "../../components/Card";

const data = [
  { day: "Mon", value: 4.6 },
  { day: "Tue", value: 6.3 },
  { day: "Wed", value: 4.8 },
  { day: "Thu", value: 7.8, peak: true },
  { day: "Fri", value: 6.1 },
  { day: "Sat", value: 4.7 },
  { day: "Sun", value: 5.2 },
];

export const ComputeActivity = () => {
  return (
    <Card className="h-96 flex flex-col">
      <div className="flex justify-between items-center mb-6 shrink-0">
        <div>
          <h3 className="font-bold text-lg text-text-main">Compute Activity</h3>
          <p className="text-xs text-text-muted mt-1 italic">
            Peak activity detected on Thursday at 7.8 Hrs
          </p>
        </div>
        <div className="flex gap-1 bg-surface-muted p-1 rounded-lg border border-border-soft">
          {["Week", "Month", "Year"].map((t) => (
            <button
              key={t}
              className={`px-3 py-1 text-[10px] font-bold rounded ${t === "Week" ? "bg-surface-white shadow-sm text-text-main" : "text-text-muted"}`}
            >
              {t}
            </button>
          ))}
        </div>
      </div>

      {/* Constraints added here to fix width(-1) error */}
      <div className="flex-1 w-full min-h-0 min-w-0">
        <ResponsiveContainer width="100%" height="100%">
          <BarChart
            data={data}
            margin={{ top: 10, right: 0, left: -20, bottom: 0 }}
          >
            <XAxis
              dataKey="day"
              axisLine={false}
              tickLine={false}
              tick={{ fontSize: 10, fontWeight: 600, fill: "#9ca3af" }}
              dy={10}
            />
            <YAxis hide domain={[0, 10]} />
            <Tooltip
              cursor={{ fill: "transparent" }}
              content={({ active, payload }) => {
                if (active && payload && payload.length) {
                  return (
                    <div className="bg-gray-900 text-white px-3 py-1.5 rounded-lg text-xs font-bold shadow-xl border border-white/10">
                      {payload[0].value} Hrs
                    </div>
                  );
                }
                return null;
              }}
            />
            <Bar dataKey="value" radius={[6, 6, 6, 6]} barSize={40}>
              {data.map((entry, index) => (
                <Cell
                  key={`cell-${index}`}
                  fill={entry.peak ? "url(#peakGradient)" : "#e5e7eb"}
                />
              ))}
            </Bar>
            <defs>
              <linearGradient id="peakGradient" x1="0" y1="0" x2="0" y2="1">
                <stop offset="0%" stopColor="#ff7d54" stopOpacity={1} />
                <stop offset="100%" stopColor="#ffb09c" stopOpacity={0.6} />
              </linearGradient>
            </defs>
          </BarChart>
        </ResponsiveContainer>
      </div>
    </Card>
  );
};
</file>

<file path="client/src/features/dashboard/JobGauge.tsx">
import { Card } from "../../components/Card";

interface Props {
  readonly total: number;
  readonly completed: number;
}

export const JobGauge = ({ total, completed }: Props) => {
  const percentage = total > 0 ? Math.round((completed / total) * 100) : 0;
  const radius = 45;
  const circumference = 2 * Math.PI * radius;
  const strokeDashoffset = circumference - (percentage / 100) * circumference;

  return (
    <Card className="flex flex-col items-center justify-center p-6 bg-surface-white">
      <div className="relative w-40 h-40 mb-4">
        {/* Rotated SVG container to start from 12 o'clock */}
        <svg className="w-full h-full -rotate-90" viewBox="0 0 128 128">
          {/* Background Track */}
          <circle
            cx="64"
            cy="64"
            r={radius}
            stroke="#f3f4f6"
            strokeWidth="12"
            fill="transparent"
            strokeLinecap="round"
          />
          {/* Active Progress */}
          <circle
            cx="64"
            cy="64"
            r={radius}
            stroke="#ff7d54"
            strokeWidth="12"
            fill="transparent"
            strokeDasharray={circumference}
            strokeDashoffset={strokeDashoffset}
            strokeLinecap="round"
            className="transition-all duration-1000 ease-out"
          />
        </svg>

        {/* Center Text (Counter-rotated to stay upright) */}
        <div className="absolute inset-0 flex flex-col items-center justify-center">
          <span className="text-3xl font-black text-text-main">{total}</span>
          <span className="text-[10px] font-bold text-text-muted uppercase tracking-widest">
            Total Jobs
          </span>
        </div>
      </div>

      <div className="w-full space-y-2 px-2">
        <div className="flex justify-between text-[10px] font-bold text-text-muted uppercase">
          <span>Progress</span>
          <span>{percentage}%</span>
        </div>
        <div className="w-full h-2 bg-gray-100 rounded-full overflow-hidden shadow-inner">
          <div
            className="h-full bg-brand-orange transition-all duration-500"
            style={{ width: `${percentage}%` }}
          />
        </div>
      </div>
    </Card>
  );
};
</file>

<file path="client/src/features/dashboard/OptimizationInsights.tsx">
import { Sparkles } from "lucide-react";
import { Card } from "../../components/Card";

interface Insight {
  id: string;
  text: string;
  isWarning?: boolean;
}

const INSIGHTS: Insight[] = [
  {
    id: "1",
    text: "Shift 3 non-urgent pipelines out of Thursday's peak window to cut ~2.1 GPU hrs.",
  },
  {
    id: "2",
    text: "Scale down idle workers between 01:00-05:00 where utilization stays below 20%.",
    isWarning: true,
  },
  {
    id: "3",
    text: "Batch short experiments (<1 min) together to reduce scheduling overhead by ~15%.",
  },
];

export const OptimizationInsights = () => (
  // STRICT THEME USAGE: Gradients use brand colors defined in theme.css
  <Card className="bg-linear-to-br from-brand-orange/10 via-brand-peach/10 to-transparent border border-brand-orange/20 relative">
    <div className="flex justify-between items-center mb-6">
      <h3 className="font-bold text-lg text-text-main">
        Optimization Insights
      </h3>
      <Sparkles size={18} className="text-brand-orange" />
    </div>

    <div className="space-y-4 mb-8">
      {INSIGHTS.map((item) => (
        <div
          key={item.id}
          className="bg-surface-white/60 backdrop-blur-md p-4 rounded-2xl border border-surface-white shadow-sm flex gap-3"
        >
          <div
            className={`w-1 rounded-full shrink-0 ${item.isWarning ? "bg-amber-400" : "bg-brand-orange"}`}
          />
          <p className="text-[11px] font-semibold leading-relaxed text-text-main">
            {item.text}
          </p>
        </div>
      ))}
    </div>

    <button className="w-full bg-text-main text-surface-white py-3.5 rounded-2xl text-xs font-bold flex items-center justify-center gap-2 hover:opacity-90 transition-all shadow-xl shadow-text-main/20 active:scale-[0.98]">
      <Sparkles size={14} className="text-brand-orange fill-brand-orange" />
      Execute all recommendations
    </button>
  </Card>
);
</file>

<file path="client/src/features/dashboard/ResourceStats.tsx">
import { Database, Zap, Activity } from "lucide-react";
import { Card } from "../../components/Card";
import { type SwarmStats } from "../../core/types";

interface Props {
  stats: SwarmStats;
  onlineCount: number;
}

export const ResourceStats = ({ stats, onlineCount }: Props) => {
  return (
    <div className="grid grid-cols-1 md:grid-cols-3 gap-5">
      <StatItem
        label="Online Nodes"
        value={onlineCount}
        icon={<Database size={18} className="text-blue-600" />}
        gradient="from-blue-50 to-blue-100/50"
        border="border-blue-100"
      />
      <StatItem
        label="Active Jobs"
        value={stats.activeJobs}
        icon={<Activity size={18} className="text-brand-orange" />}
        gradient="from-orange-50 to-orange-100/50"
        border="border-orange-100"
      />
      <StatItem
        label="Pending"
        value={stats.pendingJobs}
        icon={<Zap size={18} className="text-purple-600" />}
        gradient="from-purple-50 to-purple-100/50"
        border="border-purple-100"
      />
    </div>
  );
};

const StatItem = ({ label, value, icon, gradient, border }: any) => (
  <Card
    className={`p-5 bg-linear-to-br ${gradient} border ${border} hover:-translate-y-1 transition-transform duration-300 shadow-sm`}
  >
    <div className="flex justify-between items-start">
      <div>
        <p className="text-[10px] font-black text-text-muted uppercase tracking-widest mb-2">
          {label}
        </p>
        <p className="text-3xl font-black text-text-main tracking-tight">
          {value.toLocaleString()}
        </p>
      </div>
      <div className="p-3 bg-white rounded-xl shadow-sm border border-white/50">
        {icon}
      </div>
    </div>
  </Card>
);
</file>

<file path="client/src/features/dashboard/SwarmControls.tsx">
import { Play, Pause, Power, Square } from "lucide-react";
import { Card } from "../../components/Card";

interface SwarmControlsProps {
  readonly status: "IDLE" | "RUNNING" | "PAUSED" | "STOPPED";
  readonly onToggle: () => void;
  readonly onStop: () => void;
}

export const SwarmControls = ({
  status,
  onToggle,
  onStop,
}: SwarmControlsProps) => {
  const isRunning = status === "RUNNING";

  return (
    <Card className="p-5 bg-surface-white">
      <h3 className="font-bold text-sm text-text-muted uppercase tracking-widest mb-4">
        Master Control
      </h3>

      <div className="grid grid-cols-2 gap-4">
        {/* Toggle Button (Play/Pause) - Tactile Feel */}
        <button
          onClick={onToggle}
          className={`
            h-20 rounded-2xl flex flex-col items-center justify-center gap-2 transition-all duration-200 active:scale-[0.98]
            ${
              isRunning
                ? "bg-surface-muted shadow-inner border border-transparent" // Pressed State
                : "bg-surface-white shadow-[6px_6px_12px_#d1d5db,-6px_-6px_12px_#ffffff] border border-white" // Unpressed Pop
            }
          `}
        >
          <div
            className={`p-2 rounded-full ${isRunning ? "bg-brand-orange text-white shadow-sm" : "text-text-muted"}`}
          >
            {isRunning ? (
              <Pause size={24} fill="currentColor" />
            ) : (
              <Play size={24} fill="currentColor" className="ml-0.5" />
            )}
          </div>
          <span
            className={`text-[10px] font-black uppercase ${isRunning ? "text-brand-orange" : "text-text-muted"}`}
          >
            {isRunning ? "Pause Swarm" : "Start Swarm"}
          </span>
        </button>

        {/* Stop Button - Tactile Feel */}
        <button
          onClick={onStop}
          className="
            h-20 rounded-2xl flex flex-col items-center justify-center gap-2 transition-all duration-200 active:scale-[0.98]
            bg-surface-white shadow-[6px_6px_12px_#d1d5db,-6px_-6px_12px_#ffffff] border border-white hover:bg-red-50 group
          "
        >
          <div className="p-2 text-text-muted group-hover:text-red-500 transition-colors">
            <Square size={24} fill="currentColor" />
          </div>
          <span className="text-[10px] font-black uppercase text-text-muted group-hover:text-red-500">
            Kill Process
          </span>
        </button>
      </div>

      {/* Status LED Panel */}
      <div className="mt-6 flex items-center justify-between bg-black/5 p-3 rounded-xl shadow-inner border border-black/5">
        <span className="text-xs font-bold text-text-muted">System State</span>
        <div className="flex items-center gap-2">
          <div
            className={`w-2 h-2 rounded-full ${isRunning ? "bg-green-500 shadow-[0_0_8px_rgba(34,197,94,0.8)]" : "bg-red-500"}`}
          />
          <span className="font-mono text-xs font-bold text-text-main">
            {status}
          </span>
        </div>
      </div>
    </Card>
  );
};
</file>

<file path="client/src/features/dashboard/ThrottleControl.tsx">
import { Card } from "../../components/Card";
import { Cpu, Server, Box } from "lucide-react"; // Added Box for GPU icon

interface Props {
  value: number;
  onChange: (val: number) => void;
  totalCores: number;
  totalMemory: number;
  totalGPUs: number; // New Prop
}

export const ThrottleControl = ({
  value,
  onChange,
  totalCores = 0,
  totalMemory = 0,
  totalGPUs = 0,
}: Props) => {
  const percent = value / 100;

  return (
    <Card className="relative overflow-hidden group p-5 bg-surface-white">
      <div className="flex justify-between items-center mb-6">
        <div>
          <h3 className="font-bold text-sm text-text-muted uppercase tracking-widest">
            Global Allocation
          </h3>
          <p className="text-2xl font-black text-text-main">{value}%</p>
        </div>

        {/* Resource Badges */}
        <div className="flex flex-wrap gap-2 justify-end max-w-45">
          {/* CPU */}
          <div className="flex items-center gap-1.5 bg-gray-50 px-2 py-1 rounded-lg border border-gray-100">
            <Cpu size={12} className="text-brand-orange" />
            <span className="text-[10px] font-bold text-gray-600">
              {Math.round(totalCores * percent)} / {totalCores}
            </span>
          </div>

          {/* RAM */}
          <div className="flex items-center gap-1.5 bg-gray-50 px-2 py-1 rounded-lg border border-gray-100">
            <Server size={12} className="text-blue-500" />
            <span className="text-[10px] font-bold text-gray-600">
              {Math.round(totalMemory * percent)} GB
            </span>
          </div>

          {/* GPU (New) */}
          <div
            className={`flex items-center gap-1.5 px-2 py-1 rounded-lg border ${totalGPUs > 0 ? "bg-purple-50 border-purple-100" : "bg-gray-50 border-gray-100 opacity-50"}`}
          >
            <Box
              size={12}
              className={totalGPUs > 0 ? "text-purple-600" : "text-gray-400"}
            />
            <span
              className={`text-[10px] font-bold ${totalGPUs > 0 ? "text-purple-700" : "text-gray-400"}`}
            >
              {totalGPUs} GPU{totalGPUs !== 1 ? "s" : ""}
            </span>
          </div>
        </div>
      </div>

      <input
        type="range"
        min="10"
        max="100"
        step="10"
        value={value}
        onChange={(e) => onChange(parseInt(e.target.value))}
        className="w-full h-2 bg-gray-100 rounded-lg appearance-none cursor-pointer accent-brand-orange transition-all hover:bg-gray-200"
      />

      <div className="flex justify-between mt-3 text-[10px] font-bold text-text-muted uppercase tracking-tighter">
        <span>Eco Mode</span>
        <span>Balanced</span>
        <span>Max Performance</span>
      </div>
    </Card>
  );
};
</file>

<file path="client/src/features/dashboard/VelocityMonitor.tsx">
import { useEffect, useRef } from "react";
import { Card } from "../../components/Card";
import { Activity } from "lucide-react";

interface VelocityMonitorProps {
  readonly velocity: number;
  readonly throttle: number; // New Prop
}

export const VelocityMonitor = ({
  velocity,
  throttle,
}: VelocityMonitorProps) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const dataRef = useRef<number[]>(new Array(60).fill(0));

  // Determine Color based on Throttle
  const getColor = () => {
    if (throttle < 30) return "#22c55e"; // Green (Eco)
    if (throttle < 70) return "#ff7d54"; // Orange (Balanced)
    return "#ef4444"; // Red (Overdrive)
  };

  const activeColor = getColor();

  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    let animationFrameId: number;
    let lastDrawTime = 0;

    const draw = (timestamp: number) => {
      // ... (Keep existing frame limiting logic) ...
      if (timestamp - lastDrawTime < 33) {
        animationFrameId = requestAnimationFrame(draw);
        return;
      }
      lastDrawTime = timestamp;

      const { width, height } = canvas;
      ctx.clearRect(0, 0, width, height);

      dataRef.current.shift();
      dataRef.current.push(velocity);

      // Dynamic Gradient
      const gradient = ctx.createLinearGradient(0, 0, 0, height);
      gradient.addColorStop(0, `${activeColor}80`); // 50% opacity
      gradient.addColorStop(1, `${activeColor}00`); // 0% opacity

      ctx.beginPath();
      ctx.lineWidth = 4;
      ctx.lineCap = "round";
      ctx.lineJoin = "round";
      ctx.strokeStyle = activeColor; // Use dynamic color

      const step = width / (dataRef.current.length - 1);

      ctx.moveTo(0, height);
      dataRef.current.forEach((val, i) => {
        const x = i * step;
        const normalized = Math.min(val / 2000, 1);
        const y = height - normalized * height * 0.8 - 10;
        ctx.lineTo(x, y);
      });
      ctx.lineTo(width, height);
      ctx.fillStyle = gradient;
      ctx.fill();

      // Stroke
      ctx.beginPath();
      dataRef.current.forEach((val, i) => {
        const x = i * step;
        const normalized = Math.min(val / 2000, 1);
        const y = height - normalized * height * 0.8 - 10;
        if (i === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
      });
      ctx.stroke();

      animationFrameId = requestAnimationFrame(draw);
    };

    animationFrameId = requestAnimationFrame(draw);
    return () => cancelAnimationFrame(animationFrameId);
  }, [velocity, activeColor]); // Re-run when color changes

  return (
    <Card className="h-80 flex flex-col relative overflow-hidden bg-surface-white border border-border-soft shadow-soft-depth">
      <div className="flex justify-between items-center mb-4 z-10 px-2">
        <div>
          <h3 className="font-bold text-lg text-text-main flex items-center gap-2">
            <Activity
              className={throttle > 70 ? "text-red-500" : "text-brand-orange"}
              size={20}
            />
            Live Compute Velocity
          </h3>
          <p className="text-xs text-text-muted mt-1">
            Real-time operations per second
          </p>
        </div>
        <div className="bg-surface-muted/50 px-4 py-2 rounded-xl border border-white/50 shadow-inner backdrop-blur-sm">
          <span
            className="text-3xl font-black tabular-nums tracking-tight"
            style={{ color: activeColor }}
          >
            {velocity.toLocaleString()}
          </span>
          <span className="text-[10px] font-bold text-text-muted ml-1 uppercase">
            OPS/s
          </span>
        </div>
      </div>
      {/* ... Canvas Container ... */}
      <div className="flex-1 w-full min-h-0 relative bg-surface-muted/30 rounded-xl border border-black/5 shadow-inner overflow-hidden">
        <canvas
          ref={canvasRef}
          width={800}
          height={300}
          className="w-full h-full relative z-10"
        />
      </div>
    </Card>
  );
};
</file>

<file path="client/src/features/terminal/LiveTerminal.tsx">
import { useEffect, useRef } from "react";
import { Terminal, Activity } from "lucide-react";
import { Card } from "../../components/Card";

interface Props {
  logs: string[];
}

export const LiveTerminal = ({ logs }: Props) => {
  const scrollRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [logs]);

  return (
    <Card className="flex flex-col h-full bg-[#f8f9fa] border border-white shadow-[inset_2px_2px_5px_rgba(0,0,0,0.05),inset_-2px_-2px_5px_rgba(255,255,255,1)] rounded-2xl overflow-hidden">
      {/* Light Skeuomorphic Header */}
      <div className="flex items-center justify-between px-5 py-3 bg-[#e9ecef] border-b border-white border-t border-t-white/50 shadow-sm z-10">
        <div className="flex items-center gap-2.5">
          <div className="p-1 bg-white rounded-md shadow-sm">
            <Terminal size={12} className="text-text-muted" />
          </div>
          <span className="text-[10px] font-black text-text-muted tracking-widest uppercase">
            System Log
          </span>
        </div>
        <div className="flex items-center gap-2">
          <Activity size={12} className="text-brand-orange animate-pulse" />
          <span className="text-[9px] font-bold text-brand-orange">LIVE</span>
        </div>
      </div>

      {/* Content */}
      <div
        ref={scrollRef}
        className="flex-1 p-5 font-mono text-[11px] overflow-y-auto space-y-2 scrollbar-thin scrollbar-thumb-gray-200"
      >
        {logs.length === 0 && (
          <span className="text-gray-400 italic">Initializing kernel...</span>
        )}
        {logs.map((log, i) => (
          <div
            key={i}
            className="flex gap-3 leading-relaxed border-b border-gray-100/50 pb-1 last:border-0"
          >
            <span className="text-gray-400 select-none font-bold">
              {(i + 1).toString().padStart(3, "0")}
            </span>
            <span
              className={`font-medium ${
                log.includes("ERR")
                  ? "text-red-500"
                  : log.includes("SYS")
                    ? "text-blue-600"
                    : "text-gray-600"
              }`}
            >
              {log}
            </span>
          </div>
        ))}
      </div>
    </Card>
  );
};
</file>

<file path="client/src/hooks/useSwarmEngine.ts">
import { useEffect, useRef, useState, useCallback } from "react";
import { io, Socket } from "socket.io-client";
import {
  type SwarmSnapshot,
  type SwarmStatus,
  type DeviceInfo,
} from "../core/types";
import ComputeWorker from "../utils/compute.worker?worker"; // Import Worker

const getLocalSpecs = () => ({
  cpuCores: navigator.hardwareConcurrency || 4,
  memoryGB: (navigator as any).deviceMemory || 8,
  gpuAvailable: true,
  gpuName: "WebGPU Adapter",
});

export const useSwarmEngine = (persistentId: string) => {
  const [snapshot, setSnapshot] = useState<SwarmSnapshot | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [logs, setLogs] = useState<string[]>([]);
  const socketRef = useRef<Socket | null>(null);
  const workerRef = useRef<Worker | null>(null); // Worker Ref

  // Helper to add logs
  const addLog = (msg: string) => {
    setLogs((prev) => [...prev.slice(-19), msg]);
  };

  const [localDevice, setLocalDevice] = useState<DeviceInfo>({
    id: persistentId,
    name: "Local Host",
    type: "DESKTOP",
    status: "ONLINE",
    capabilities: getLocalSpecs(),
    opsScore: 0, // Starts at 0
    totalJobsCompleted: 0,
    lastHeartbeat: 0,
  });

  // --- WORKER SETUP ---
  useEffect(() => {
    const worker = new ComputeWorker();
    workerRef.current = worker;

    worker.onmessage = (e) => {
      const { type, score } = e.data;
      if (type === "BENCHMARK_COMPLETE") {
        addLog(`[SYS] Benchmark Finished: ${score} OPS`);
        // UPDATE LOCAL STATE IMMEDIATELY
        setLocalDevice((prev) => ({ ...prev, opsScore: score }));
        // Tell server
        socketRef.current?.emit("benchmark:result", { score });
      }
    };

    return () => worker.terminate();
  }, []);

  const connect = useCallback(() => {
    if (socketRef.current?.connected) return;

    socketRef.current = io(
      import.meta.env.VITE_SERVER_URL || "http://localhost:3000",
      {
        query: { persistentId },
        transports: ["websocket"],
        reconnection: true,
      },
    );

    socketRef.current.on("connect", () => {
      setIsConnected(true);
      addLog("[SYS] Connected to Coordinator");
      socketRef.current?.emit("device:register", {
        name: "Local Host",
        capabilities: getLocalSpecs(),
      });
    });

    socketRef.current.on("disconnect", () => {
      setIsConnected(false);
      addLog("[ERR] Connection Lost");
    });

    socketRef.current.on("swarm:snapshot", (data: SwarmSnapshot) => {
      setSnapshot(data);
    });
  }, [persistentId]);

  useEffect(() => {
    connect();
    return () => {
      if (socketRef.current) {
        socketRef.current.removeAllListeners();
        socketRef.current.disconnect();
        socketRef.current = null;
      }
    };
  }, [connect]);

  useEffect(() => {
    if (!isConnected) return;
    const interval = setInterval(
      () => socketRef.current?.emit("heartbeat"),
      2000,
    );
    return () => clearInterval(interval);
  }, [isConnected]);

  // Actions
  const setRunState = (state: SwarmStatus) => {
    socketRef.current?.emit("cmd:set_run_state", state);
  };

  const runLocalBenchmark = () => {
    addLog("[SYS] Running Local Benchmark...");
    // Trigger the worker directly
    workerRef.current?.postMessage({ type: "BENCHMARK" });
  };

  // Merge Devices (Server + Updated Local)
  const serverDevices = snapshot ? Object.values(snapshot.devices) : [];
  const allDevices = [
    localDevice, // Always put local first
    ...serverDevices.filter((d) => d.id !== persistentId),
  ];

  const totalResources = snapshot?.resources || {
    totalCores: localDevice.capabilities.cpuCores,
    totalMemory: localDevice.capabilities.memoryGB,
    totalGPUs: localDevice.capabilities.gpuAvailable ? 1 : 0,
    onlineCount: 1,
  };

  return {
    snapshot,
    devices: allDevices,
    setRunState,
    runLocalBenchmark,
    isConnected,
    toggleDevice: (id: string, enabled: boolean) =>
      socketRef.current?.emit("cmd:toggle_device", { id, enabled }),
    totalResources,
    logs,
  };
};
</file>

<file path="client/src/hooks/useSwarmExecution.ts">
import { useEffect, useRef, useCallback } from "react";
import ComputeWorker from "../utils/compute.worker?worker";

export const useSwarmExecution = (throttle: number, isRunning: boolean) => {
  const workerRef = useRef<Worker | null>(null);

  const updateConfig = useCallback(() => {
    workerRef.current?.postMessage({
      type: "CONFIG_UPDATE",
      payload: { throttle: isRunning ? throttle / 100 : 0 },
    });
  }, [throttle, isRunning]);

  useEffect(() => {
    const worker = new ComputeWorker();
    workerRef.current = worker;

    // Fix Bottleneck 1: Pause when tab is backgrounded
    const handleVisibility = () => {
      if (document.hidden) {
        worker.postMessage({ type: "CONFIG_UPDATE", payload: { throttle: 0 } });
      } else {
        updateConfig();
      }
    };

    document.addEventListener("visibilitychange", handleVisibility);
    updateConfig();

    return () => {
      document.removeEventListener("visibilitychange", handleVisibility);
      worker.terminate();
    };
  }, [updateConfig]);

  return {
    dispatchJob: (job: any) => {
      workerRef.current?.postMessage({ type: "EXECUTE_JOB", payload: job });
    },
  };
};
</file>

<file path="client/src/utils/compute.worker.ts">
/// <reference lib="webworker" />

// --- CONFIGURATION ---
const LOGICAL_CORES = navigator.hardwareConcurrency || 4;

// --- STATE ---
const threadPool = new Map<
  number,
  { worker: Worker; objectUrl: string; busy: boolean }
>();
let throttleLimit = 0.3; // Default 30%
let nextWorkerId = 0;

// --- GPU KERNEL (WGSL) ---
const WGSL_SHADER = `
@group(0) @binding(0) var<storage, read> matrixA : array<f32>;
@group(0) @binding(1) var<storage, read> matrixB : array<f32>;
@group(0) @binding(2) var<storage, read_write> result : array<f32>;
@group(0) @binding(3) var<uniform> uniforms : vec2<f32>;

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) global_id : vec3<u32>) {
  let index = global_id.x;
  let size = u32(uniforms.x);
  
  if (index >= size * size) { return; }

  let row = index / size;
  let col = index % size;
  var sum = 0.0; // FIXED: Changed 'let' to 'var' to allow mutation

  for (var k = 0u; k < size; k = k + 1u) {
    sum = sum + matrixA[row * size + k] * matrixB[k * size + col];
  }

  result[index] = sum;
}
`;

// --- SUB-WORKER FACTORY ---
const createSubWorker = (_wId: number) => {
  const blob = new Blob(
    [
      `
    // --- SHARED STATE ---
    let throttleLevel = 1.0; 

    // --- CPU KERNELS (Fallback) ---
    const runCpuStress = (iterations) => {
      let sum = 0;
      const count = iterations || 100000;
      for (let i = 0; i < count; i++) {
        sum += Math.sqrt(i) * Math.sin(i);
      }
      return sum;
    };

    const runCpuMatrix = (size) => {
       // Simulate CPU load for matrix math
       const totalOps = size * size * size;
       let dummy = 0;
       // Artificial delay to simulate work
       const end = performance.now() + (totalOps / 1000000); 
       while(performance.now() < end) {
         dummy += Math.random();
       }
       return dummy;
    };

    // --- GPU CONTEXT ---
    let device = null;
    let computePipeline = null;
    let gpuReady = false;

    async function initWebGPU() {
      if (!navigator.gpu) return false;
      const adapter = await navigator.gpu.requestAdapter();
      if (!adapter) return false;
      device = await adapter.requestDevice();
      
      const shaderModule = device.createShaderModule({ 
        code: \`${WGSL_SHADER}\` 
      });
      
      computePipeline = device.createComputePipeline({
        layout: 'auto',
        compute: { module: shaderModule, entryPoint: "main" }
      });
      return true;
    }

    initWebGPU().then(ok => gpuReady = ok);

    async function runGpuMatrix(size) {
      if (!gpuReady || !device) return runCpuMatrix(size);

      const matrixSize = size * size;
      const resultSize = matrixSize * 4; 

      // 1. Create & Map Buffers
      // In a real app we would copy data here. For simulation, we assume active VRAM usage.
      const gpuBufferA = device.createBuffer({ size: resultSize, usage: GPUBufferUsage.STORAGE, mappedAtCreation: true });
      new Float32Array(gpuBufferA.getMappedRange()).fill(1.5);
      gpuBufferA.unmap();

      const gpuBufferB = device.createBuffer({ size: resultSize, usage: GPUBufferUsage.STORAGE, mappedAtCreation: true });
      new Float32Array(gpuBufferB.getMappedRange()).fill(2.5);
      gpuBufferB.unmap();

      const resultBuffer = device.createBuffer({ size: resultSize, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
      
      const uniformBuffer = device.createBuffer({ mappedAtCreation: true, size: 16, usage: GPUBufferUsage.UNIFORM });
      new Float32Array(uniformBuffer.getMappedRange()).set([size, size]);
      uniformBuffer.unmap();

      // 2. Bind Group
      const bindGroup = device.createBindGroup({
        layout: computePipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: gpuBufferA } },
          { binding: 1, resource: { buffer: gpuBufferB } },
          { binding: 2, resource: { buffer: resultBuffer } },
          { binding: 3, resource: { buffer: uniformBuffer } },
        ]
      });

      // 3. Dispatch
      const commandEncoder = device.createCommandEncoder();
      const passEncoder = commandEncoder.beginComputePass();
      passEncoder.setPipeline(computePipeline);
      passEncoder.setBindGroup(0, bindGroup);
      passEncoder.dispatchWorkgroups(Math.ceil(matrixSize / 64));
      passEncoder.end();

      device.queue.submit([commandEncoder.finish()]);
      
      // 4. Wait (Fence)
      await device.queue.onSubmittedWorkDone();
      return 1; 
    }

    self.onmessage = async (e) => {
      const { type, data, _throttle, throttleLevel: altThrottle } = e.data;
      
      // Ensure throttle is captured regardless of property name used
      if (_throttle !== undefined) throttleLevel = _throttle;
      else if (altThrottle !== undefined) throttleLevel = altThrottle;

      let result = 0;

      try {
        if (type === "MAT_MUL") {
             // Use GPU if available
             if (gpuReady && device) {
                 await runGpuMatrix(data.size || 256);
                 result = 1; 
             } else {
                 result = runCpuMatrix(data.size || 256);
             }
        } 
        else if (type === "MATH_STRESS") {
             result = runCpuStress(data.iterations);
        }
        else if (type === "BENCHMARK") {
             const start = performance.now();
             // Run at full power for the benchmark to see true capability
             if (gpuReady && device) {
                 await runGpuMatrix(1024); 
                 const duration = (performance.now() - start) / 1000;
                 result = Math.round(5000 / (duration + 0.001)); // Higher base for GPU
             } else {
                 runCpuStress(5000000);
                 const duration = (performance.now() - start) / 1000; 
                 result = Math.round(1000 / (duration + 0.001));
             }

             self.postMessage({
               type: "BENCHMARK_COMPLETE",
               score: result // Send the RAW score, don't multiply by throttleLevel here
             });
             return; 
        }
        
        self.postMessage({ success: true, result });

      } catch (err) {
        self.postMessage({ success: false, error: err.message });
      }
    }
  `,
    ],
    { type: "application/javascript" },
  );

  const objectUrl = URL.createObjectURL(blob);
  return { worker: new Worker(objectUrl), objectUrl };
};

// --- MANAGER: MANAGES THE THREAD POOL ---
const applyConfig = () => {
  // Scale thread count based on throttle
  const targetThreadCount = Math.max(
    1,
    Math.floor(LOGICAL_CORES * throttleLimit),
  );

  // 1. EXPAND POOL
  if (targetThreadCount > threadPool.size) {
    for (let i = threadPool.size; i < targetThreadCount; i++) {
      const wId = nextWorkerId++;
      const { worker, objectUrl } = createSubWorker(wId);

      // Initialize with current throttle
      worker.postMessage({ type: "UPDATE_CONFIG", _throttle: throttleLimit });

      worker.onmessage = (ev) => {
        const msg = ev.data;
        if (msg.type === "BENCHMARK_COMPLETE") {
          self.postMessage(msg); // Forward to main thread
        } else if (msg.success || msg.error) {
          const t = threadPool.get(wId);
          if (t) t.busy = false;
          // We don't have the chunkId here in a generic handler,
          // but the specific job handler below handles the 'JOB_COMPLETE'
        }
      };
      threadPool.set(wId, { worker, objectUrl, busy: false });
    }
  }
  // 2. SHRINK POOL
  else if (targetThreadCount < threadPool.size) {
    const toRemove = threadPool.size - targetThreadCount;
    let removed = 0;
    for (const [id, thread] of threadPool.entries()) {
      if (!thread.busy && removed < toRemove) {
        thread.worker.terminate();
        URL.revokeObjectURL(thread.objectUrl);
        threadPool.delete(id);
        removed++;
      }
    }
  }
};

// Initial Setup
applyConfig();

// --- MAIN LISTENER (From UI Thread) ---
self.onmessage = async (e) => {
  const { type, payload } = e.data;

  // 1. CONFIG UPDATE
  if (type === "CONFIG_UPDATE") {
    throttleLimit = payload.throttle;
    applyConfig();

    // Broadcast new throttle to all sub-workers so benchmarks scale
    threadPool.forEach(({ worker }) => {
      worker.postMessage({ type: "UPDATE_CONFIG", _throttle: throttleLimit });
    });
    return;
  }

  // 2. BENCHMARK TRIGGER
  if (type === "BENCHMARK") {
    // Pick the first available worker to run the benchmark
    const iterator = threadPool.values();
    const first = iterator.next().value;
    if (first) {
      first.worker.postMessage({ type: "BENCHMARK", _throttle: throttleLimit });
    }
    return;
  }

  // 3. JOB EXECUTION
  if (type === "EXECUTE_JOB") {
    // Find free worker
    let selectedId = -1;
    for (const [id, thread] of threadPool.entries()) {
      if (!thread.busy) {
        selectedId = id;
        break;
      }
    }

    if (selectedId === -1) return; // Drop job if all busy (or queue it)

    const jobData = payload; // payload contains the job info

    const thread = threadPool.get(selectedId)!;
    thread.busy = true;

    const originalHandler = thread.worker.onmessage;
    thread.worker.onmessage = (ev) => {
      thread.busy = false;
      thread.worker.onmessage = originalHandler;

      self.postMessage({
        type: ev.data.success ? "JOB_COMPLETE" : "JOB_ERROR",
        chunkId: jobData.id,
        result: ev.data.result,
        error: ev.data.error,
      });
    };

    thread.worker.postMessage({
      type: jobData.type,
      data: jobData.data,
      _throttle: throttleLimit,
    });
  }
};
</file>

<file path="client/tsconfig.app.json">
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.app.tsbuildinfo",
    "target": "ES2022",
    "useDefineForClassFields": true,
    "lib": ["ES2022", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "types": ["vite/client"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["src"]
}
</file>

<file path="client/tsconfig.json">
{
  "files": [],
  "references": [
    { "path": "./tsconfig.app.json" },
    { "path": "./tsconfig.node.json" }
  ]
}
</file>

<file path="client/tsconfig.node.json">
{
  "compilerOptions": {
    "tsBuildInfoFile": "./node_modules/.tmp/tsconfig.node.tsbuildinfo",
    "target": "ES2023",
    "lib": ["ES2023"],
    "module": "ESNext",
    "types": ["node"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  },
  "include": ["vite.config.ts"]
}
</file>

<file path="Resource_share-COLAB.ipynb">
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh_ss-Sq2pN9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CmKm_o41_8T",
        "outputId": "cc41c109-c90e-4631-a457-0c804a1f8be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/82.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/59.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install python-socketio --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ostrich Legs Worker Node (v4.0 - Adaptive Benchmark & Polling)\n",
        "# @markdown Run this cell to join the compute swarm!\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import threading\n",
        "import platform\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. INSTALL DEPENDENCIES ---\n",
        "try:\n",
        "    import socketio\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-socketio[client]\", \"requests\"])\n",
        "    import socketio\n"
      ],
      "metadata": {
        "id": "WhzaxOm_QbZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try importing Torch for GPU support\n",
        "HAS_GPU = False\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        HAS_GPU = True\n",
        "        print(f\"ðŸš€ GPU DETECTED: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ GPU not found. Falling back to CPU.\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ PyTorch not installed. Falling back to CPU.\")\n"
      ],
      "metadata": {
        "id": "VTIB47esQgO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. KERNELS ---\n",
        "\n",
        "def run_stress_test(iterations):\n",
        "    \"\"\"CPU Bound Stress Test\"\"\"\n",
        "    start = time.time()\n",
        "    count = int(iterations or 100000)\n",
        "    # CPU heavy vector math\n",
        "    x = np.random.rand(int(count/100))\n",
        "    np.sin(x) * np.sqrt(x)\n",
        "    return float(time.time() - start)\n",
        "\n",
        "def run_matrix_mul(data):\n",
        "    \"\"\"Hybrid GPU/CPU Matrix Multiplication\"\"\"\n",
        "    start = time.time()\n",
        "\n",
        "    # Extract dimensions (default 300 for normal jobs)\n",
        "    size = int(data.get('size', 300))\n",
        "\n",
        "    if HAS_GPU:\n",
        "        # GPU PATH\n",
        "        a = torch.rand(size, size, device='cuda')\n",
        "        b = torch.rand(size, size, device='cuda')\n",
        "        torch.matmul(a, b)\n",
        "        torch.cuda.synchronize()\n",
        "    else:\n",
        "        # CPU PATH\n",
        "        a = np.random.rand(size, size)\n",
        "        b = np.random.rand(size, size)\n",
        "        np.dot(a, b)\n",
        "\n",
        "    return float(time.time() - start)\n",
        "\n",
        "def process_job(job):\n",
        "    global last_work_time\n",
        "    if not sio.connected: return False\n",
        "\n",
        "    job_id = job['id']\n",
        "    job_type = job['type']\n",
        "    job_data = job['data']\n",
        "\n",
        "    try:\n",
        "        duration = 0\n",
        "        if job_type == 'MATH_STRESS':\n",
        "            duration = run_stress_test(job_data.get('iterations', 50000))\n",
        "        elif job_type == 'MAT_MUL':\n",
        "            duration = run_matrix_mul(job_data)\n",
        "\n",
        "        last_work_time = time.time()\n",
        "\n",
        "        if sio.connected:\n",
        "            sio.emit('job:complete', {\n",
        "                'chunkId': job_id,\n",
        "                'result': 'Calculated',\n",
        "                'durationMs': duration * 1000,\n",
        "                'workerId': DEVICE_ID,\n",
        "                'timestamp': time.time() * 1000\n",
        "            })\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"\\nJob Error: {e}\")\n",
        "        if sio.connected:\n",
        "            sio.emit('job:complete', {\n",
        "                'chunkId': job_id,\n",
        "                'error': str(e),\n",
        "                'workerId': DEVICE_ID\n",
        "            })\n",
        "        return False\n",
        "\n",
        "# --- 5. EVENTS ---\n",
        "\n",
        "@sio.event\n",
        "def connect():\n",
        "    print(f\"\\nâœ… Connected! ID: {DEVICE_ID}\")\n",
        "\n",
        "    # Detect System Info\n",
        "    import multiprocessing\n",
        "    cores = multiprocessing.cpu_count()\n",
        "    mem = 12\n",
        "\n",
        "    sio.emit('device:register', {\n",
        "        'name': DEVICE_NAME,\n",
        "        'type': 'COLAB',\n",
        "        'capabilities': {\n",
        "            'cpuCores': cores,\n",
        "            'memoryGB': mem,\n",
        "            'gpuAvailable': HAS_GPU,\n",
        "            # If GPU, we can handle huge concurrency because CUDA is parallel\n",
        "            'maxConcurrency': cores * 4 if HAS_GPU else cores,\n",
        "            'supportedJobs': ['MATH_STRESS', 'MAT_MUL']\n",
        "        }\n",
        "    })\n",
        "\n",
        "@sio.on('job:batch')\n",
        "def on_batch(jobs):\n",
        "    global is_working\n",
        "    is_working = True\n",
        "    print(f\"\\rðŸ“¦ Batch: {len(jobs)} | GPU: {'ON' if HAS_GPU else 'OFF'}\", end=\"\")\n",
        "\n",
        "    for job in jobs:\n",
        "        if not sio.connected: break\n",
        "        process_job(job)\n",
        "\n",
        "    is_working = False\n",
        "\n",
        "    # Pull next batch\n",
        "    if sio.connected:\n",
        "        sio.emit('job:request_batch')\n",
        "\n",
        "@sio.on('cmd:run_benchmark')\n",
        "def on_benchmark():\n",
        "    print(\"\\nðŸš€ Starting Benchmark...\", end=\"\")\n",
        "    try:\n",
        "        start = time.time()\n",
        "        score = 0\n",
        "\n",
        "        if HAS_GPU:\n",
        "            # CASE A: GPU (Heavy Matrix Mul)\n",
        "            size = 1000\n",
        "            a = torch.rand(size, size, device='cuda')\n",
        "            b = torch.rand(size, size, device='cuda')\n",
        "            torch.matmul(a, b)\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            duration = time.time() - start\n",
        "            # Formula: 2 Billion Ops / Seconds\n",
        "            score = int(2000000000 / (duration + 0.00001))\n",
        "            print(f\" [GPU MODE] Score: {score:,}\")\n",
        "\n",
        "        else:\n",
        "            # CASE B: CPU (Simple Loop)\n",
        "            # 5 Million Iterations\n",
        "            count = 5000000\n",
        "            x = np.random.rand(int(count/100))\n",
        "            np.sin(x) * np.sqrt(x)\n",
        "\n",
        "            duration = time.time() - start\n",
        "            # Formula: Iterations / Seconds\n",
        "            score = int(count / (duration + 0.00001))\n",
        "            print(f\" [CPU MODE] Score: {score:,}\")\n",
        "\n",
        "        sio.emit('benchmark:result', {'score': score})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Benchmark Failed: {e}\")\n",
        "\n",
        "@sio.event\n",
        "def disconnect():\n",
        "    print(\"\\nâŒ Disconnected from server.\")\n",
        "\n",
        "# --- 6. BACKGROUND POLLER ---\n",
        "def poller_loop():\n",
        "    while True:\n",
        "        try:\n",
        "            # If idle for >1s, ask for work\n",
        "            if sio.connected and not is_working:\n",
        "                if time.time() - last_work_time > 1.0:\n",
        "                    sio.emit('job:request_batch')\n",
        "            time.sleep(1.0)\n",
        "        except:\n",
        "            pass\n"
      ],
      "metadata": {
        "id": "ou5a0ug1Qsqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. IDENTITY ---\n",
        "id_file = \"device_identity.txt\"\n",
        "if os.path.exists(id_file):\n",
        "    with open(id_file, \"r\") as f:\n",
        "        DEVICE_ID = f.read().strip()\n",
        "else:\n",
        "    DEVICE_ID = f\"colab-{str(uuid.uuid4())[:8]}\"\n",
        "    with open(id_file, \"w\") as f:\n",
        "        f.write(DEVICE_ID)\n",
        "\n",
        "sio = socketio.Client(reconnection=True, reconnection_delay=5)\n",
        "is_working = False\n",
        "last_work_time = time.time()\n"
      ],
      "metadata": {
        "id": "3x1KtBgcQvKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. CONFIGURATION ---\n",
        "SERVER_URL = \"https://public-pride-bought-sys.trycloudflare.com/\" # @param {type:\"string\"}\n",
        "DEVICE_NAME = \"Colab-Node-01\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "# --- 7. MAIN START ---\n",
        "def main():\n",
        "    print(f\"ðŸš€ Initializing Worker {DEVICE_ID}...\")\n",
        "\n",
        "    # Start Poller\n",
        "    t = threading.Thread(target=poller_loop, daemon=True)\n",
        "    t.start()\n",
        "\n",
        "    # Auth URL\n",
        "    auth_url = f\"{SERVER_URL}?persistentId={DEVICE_ID}\"\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            if not sio.connected:\n",
        "                print(f\"Connecting to {SERVER_URL}...\")\n",
        "                sio.connect(auth_url, transports=['websocket', 'polling'])\n",
        "                sio.wait()\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nStopping...\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Connection Error: {e}\")\n",
        "            time.sleep(5)\n"
      ],
      "metadata": {
        "id": "5zJYP80nQ3Z8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "dfTz0baT1GI1",
        "collapsed": true,
        "outputId": "eaf27aba-a478-4785-e2b5-82adfa6fcdbd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'main' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-217905245.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Fi0UHRcQ_ws"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
</file>

<file path="server/src/core/types.ts">
export type DeviceType = "DESKTOP" | "MOBILE" | "COLAB" | "SERVER";
export type JobType = "MATH_STRESS" | "MAT_MUL" | "TEXT_TOKENIZE";

export interface DeviceCapabilities {
  cpuCores: number;
  memoryGB: number;
  gpuAvailable: boolean;
  gpuName?: string;
}

export interface DeviceInfo {
  id: string;
  name: string;
  type: DeviceType;
  status: "ONLINE" | "BUSY" | "OFFLINE" | "DISABLED";
  capabilities: DeviceCapabilities;
  opsScore: number;
  totalJobsCompleted: number;
  lastHeartbeat: number;
}

export interface SwarmResources {
  totalCores: number;
  totalMemory: number;
  totalGPUs: number;
  onlineCount: number;
}

export interface Job {
  id: string;
  type: JobType;
  complexity: number;
  data: any;
}

export interface SwarmSnapshot {
  runState: "IDLE" | "RUNNING" | "PAUSED" | "STOPPED";
  devices: Record<string, DeviceInfo>;
  stats: {
    totalJobs: number;
    activeJobs: number;
    pendingJobs: number;
    completedJobs: number;
    globalVelocity: number;
  };
  resources: SwarmResources;
}
</file>

<file path="server/src/managers/DeviceManager.ts">
import { type DeviceInfo, type DeviceCapabilities } from "../core/types";

export class DeviceManager {
  private devices = new Map<string, DeviceInfo>();
  private HEATBEAT_TIMEOUT = 10000; // 10s offline threshold

  constructor() {
    // Heartbeat Pulse Check every 5s
    setInterval(() => this.checkHeartbeats(), 5000);
  }

  public register(id: string, name: string, caps: DeviceCapabilities) {
    const existing = this.devices.get(id);
    this.devices.set(id, {
      id,
      name,
      type: caps.gpuAvailable ? "SERVER" : "DESKTOP",
      status: existing?.status === "DISABLED" ? "DISABLED" : "ONLINE",
      capabilities: caps,
      opsScore: existing?.opsScore || 0,
      totalJobsCompleted: existing?.totalJobsCompleted || 0,
      lastHeartbeat: Date.now(),
    });
  }

  public heartbeat(id: string) {
    const device = this.devices.get(id);
    if (device && device.status !== "DISABLED") {
      device.lastHeartbeat = Date.now();
      if (device.status === "OFFLINE") device.status = "ONLINE";
    }
  }

  public toggleDevice(id: string, enabled: boolean) {
    const device = this.devices.get(id);
    if (device) {
      device.status = enabled ? "ONLINE" : "DISABLED";
    }
  }

  public updateScore(id: string, score: number) {
    const device = this.devices.get(id);
    if (device) device.opsScore = score;
  }

  public getAvailableResources() {
    let totalCores = 0;
    let totalMemory = 0;
    let totalGPUs = 0;
    let onlineCount = 0;

    this.devices.forEach((d) => {
      if (d.status === "ONLINE" || d.status === "BUSY") {
        totalCores += d.capabilities.cpuCores;
        totalMemory += d.capabilities.memoryGB;
        if (d.capabilities.gpuAvailable) totalGPUs++;
        onlineCount++;
      }
    });

    return { totalCores, totalMemory, totalGPUs, onlineCount };
  }

  public getAllDevices() {
    return Array.from(this.devices.values());
  }

  private checkHeartbeats() {
    const now = Date.now();
    this.devices.forEach((device) => {
      if (
        device.status !== "DISABLED" &&
        now - device.lastHeartbeat > this.HEATBEAT_TIMEOUT
      ) {
        device.status = "OFFLINE";
      }
    });
  }
}
</file>

<file path="server/src/managers/JobScheduler.ts">
import { type Job, type DeviceInfo } from "../core/types";

export class JobScheduler {
  private jobQueue: Job[] = [];

  constructor() {
    // Generate dummy jobs periodically (Low overhead: just pushing objects)
    setInterval(() => this.generateJobs(), 2000);
  }

  private generateJobs() {
    if (this.jobQueue.length > 500) return; // Prevent memory overflow

    // Create 50 lightweight job objects
    for (let i = 0; i < 50; i++) {
      const isGpuTask = Math.random() > 0.7; // 30% GPU tasks
      this.jobQueue.push({
        id: `job-${Date.now()}-${Math.random().toString(36).substr(2, 5)}`,
        type: isGpuTask ? "MAT_MUL" : "MATH_STRESS",
        complexity: Math.floor(Math.random() * 10) + 1,
        data: isGpuTask ? { size: 1024 } : { iterations: 100000 },
      });
    }
  }

  public getJobForDevice(device: DeviceInfo): Job | null {
    if (device.status === "DISABLED" || device.status === "OFFLINE")
      return null;

    // Capability-based Scheduling
    const preferredType = device.capabilities.gpuAvailable
      ? "MAT_MUL"
      : "MATH_STRESS";

    // Find best match
    const index = this.jobQueue.findIndex((j) => j.type === preferredType);

    if (index !== -1) {
      return this.jobQueue.splice(index, 1)[0];
    }

    // Fallback: take any job
    return this.jobQueue.shift() || null;
  }

  public getQueueStats() {
    return {
      pending: this.jobQueue.length,
      active: 0, // In a real DB this would be tracked
    };
  }
}
</file>

<file path="server/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2023",
    "lib": ["ES2023"],
    "module": "ESNext",
    "types": ["node"],
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "moduleDetection": "force",
    "noEmit": true,

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "erasableSyntaxOnly": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedSideEffectImports": true
  }
}
</file>

<file path="client/package.json">
{
  "name": "client",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite --host",
    "build": "tsc -b && vite build",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@tailwindcss/vite": "^4.1.18",
    "clsx": "^2.1.1",
    "framer-motion": "^12.33.0",
    "lucide-react": "^0.563.0",
    "qrcode.react": "^4.2.0",
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "recharts": "^3.7.0",
    "socket.io-client": "^4.8.3",
    "tailwind-merge": "^3.4.0",
    "tailwindcss": "^4.1.18"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.1",
    "@types/node": "^24.10.1",
    "@types/react": "^19.2.5",
    "@types/react-dom": "^19.2.3",
    "@vitejs/plugin-react-swc": "^4.2.2",
    "eslint": "^9.39.1",
    "eslint-plugin-react-hooks": "^7.0.1",
    "eslint-plugin-react-refresh": "^0.4.24",
    "globals": "^16.5.0",
    "typescript": "~5.9.3",
    "typescript-eslint": "^8.46.4",
    "vite": "^7.2.4"
  }
}
</file>

<file path="client/src/main.tsx">
import { StrictMode } from "react";
import { createRoot } from "react-dom/client";
import "./core/theme.css";
import App from "./App.tsx";

createRoot(document.getElementById("root")!).render(
  <StrictMode>
    <App />
  </StrictMode>,
);
</file>

<file path="client/vite.config.ts">
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react-swc";
import tailwindcss from "@tailwindcss/vite";

// https://vite.dev/config/
export default defineConfig({
  plugins: [react(), tailwindcss()],
  server: {
    proxy: {
      // Forward all requests starting with /api to the backend
      "/api": {
        target: "http://localhost:3000",
        changeOrigin: true,
      },
      // Also proxy the socket.io connection
      "/socket.io": {
        target: "http://localhost:3000",
        ws: true,
      },
    },
  },
});
</file>

<file path="server/package.json">
{
  "name": "ostrich-server",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "bun src/index.ts"
  },
  "dependencies": {
    "cors": "^2.8.6",
    "express": "^5.2.1",
    "http": "^0.0.1-security",
    "socket.io": "^4.8.3"
  },
  "devDependencies": {
    "@types/cors": "^2.8.13",
    "@types/express": "^4.17.17",
    "@types/node": "^25.2.1",
    "ts-node": "^10.9.1",
    "typescript": "^5.1.6"
  }
}
</file>

<file path="client/src/utils/worker.ts">
/// <reference lib="webworker" />

// --- CONFIGURATION ---
const LOGICAL_CORES = navigator.hardwareConcurrency || 4;

// --- STATE ---
const threadPool = new Map<
  number,
  { worker: Worker; objectUrl: string; busy: boolean }
>();
let throttleLimit = 0.3;
let nextWorkerId = 0;

// --- GPU KERNEL (WGSL) ---
const WGSL_SHADER = `
@group(0) @binding(0) var<storage, read> matrixA : array<f32>;
@group(0) @binding(1) var<storage, read> matrixB : array<f32>;
@group(0) @binding(2) var<storage, read_write> result : array<f32>;
@group(0) @binding(3) var<uniform> uniforms : vec2<f32>; // [width, height]

@compute @workgroup_size(64)
fn main(@builtin(global_invocation_id) global_id : vec3<u32>) {
  let index = global_id.x;
  let size = u32(uniforms.x);
  
  if (index >= size * size) { return; }

  let row = index / size;
  let col = index % size;
  let sum = 0.0;

  for (let k = 0u; k < size; k = k + 1u) {
    sum = sum + matrixA[row * size + k] * matrixB[k * size + col];
  }

  result[index] = sum;
}
`;

// --- SUB-WORKER FACTORY ---
const createSubWorker = (_wId: number) => {
  const blob = new Blob(
    [
      `
    // --- CPU KERNELS (Fallback) ---
    const runCpuStress = (iterations) => {
      let sum = 0;
      const count = iterations || 100000;
      for (let i = 0; i < count; i++) {
        sum += Math.sqrt(i) * Math.sin(i);
      }
      return sum;
    };

    const runCpuMatrix = (size) => {
       const dummy = new Float32Array(size * size);
       for(let i=0; i<1000; i++) Math.random(); 
       return dummy;
    };

    // --- GPU CONTEXT ---
    let device = null;
    let computePipeline = null;

    async function initWebGPU() {
      if (!navigator.gpu) return false;
      const adapter = await navigator.gpu.requestAdapter();
      if (!adapter) return false;
      device = await adapter.requestDevice();
      
      const shaderModule = device.createShaderModule({ 
        code: \`${WGSL_SHADER}\` 
      });
      
      computePipeline = device.createComputePipeline({
        layout: 'auto',
        compute: { module: shaderModule, entryPoint: "main" }
      });
      return true;
    }

    let gpuReady = false;
    initWebGPU().then(ok => gpuReady = ok);

    async function runGpuMatrix(size) {
      if (!gpuReady || !device) return runCpuMatrix(size);

      // 1. Create Data (Simplified for Benchmark)
      const matrixSize = size * size;
      // We don't fill real data to save time, just allocate
      const resultSize = matrixSize * 4; 

      // 2. Create Buffers
      const gpuBufferA = device.createBuffer({ size: resultSize, usage: GPUBufferUsage.STORAGE, mappedAtCreation: true });
      new Float32Array(gpuBufferA.getMappedRange()).fill(1.5);
      gpuBufferA.unmap();

      const gpuBufferB = device.createBuffer({ size: resultSize, usage: GPUBufferUsage.STORAGE, mappedAtCreation: true });
      new Float32Array(gpuBufferB.getMappedRange()).fill(2.5);
      gpuBufferB.unmap();

      const resultBuffer = device.createBuffer({ size: resultSize, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC });
      
      const uniformBuffer = device.createBuffer({ mappedAtCreation: true, size: 16, usage: GPUBufferUsage.UNIFORM });
      new Float32Array(uniformBuffer.getMappedRange()).set([size, size]);
      uniformBuffer.unmap();

      // 3. Bind Group
      const bindGroup = device.createBindGroup({
        layout: computePipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: gpuBufferA } },
          { binding: 1, resource: { buffer: gpuBufferB } },
          { binding: 2, resource: { buffer: resultBuffer } },
          { binding: 3, resource: { buffer: uniformBuffer } },
        ]
      });

      // 4. Dispatch
      const commandEncoder = device.createCommandEncoder();
      const passEncoder = commandEncoder.beginComputePass();
      passEncoder.setPipeline(computePipeline);
      passEncoder.setBindGroup(0, bindGroup);
      passEncoder.dispatchWorkgroups(Math.ceil(matrixSize / 64));
      passEncoder.end();

      device.queue.submit([commandEncoder.finish()]);
      
      // Wait for completion (using mapAsync as a "fence")
      const gpuReadBuffer = device.createBuffer({ size: 4, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ });
      // We don't actually copy everything back, just wait for queue
      await gpuReadBuffer.mapAsync(GPUMapMode.READ);
      return 1; 
    }

    self.onmessage = async (e) => {
      const { type, data } = e.data;
      let result = 0;

      try {
        if (type === "MAT_MUL" && data.size) {
             result = await runGpuMatrix(data.size);
        } 
        else if (type === "MATH_STRESS") {
             result = runCpuStress(data.iterations);
        }
        else if (type === "BENCHMARK") {
             const start = performance.now();
             let score = 0;

             if (gpuReady && device) {
                 // CASE A: GPU (1000x1000 Matrix)
                 // ~2 Billion Operations
                 await runGpuMatrix(1000); 
                 const duration = (performance.now() - start) / 1000;
                 score = Math.round(2000000000 / (duration || 0.001));
             } 
             else {
                 // CASE B: CPU (Simple Loop)
                 const iterations = 5000000;
                 runCpuStress(iterations);
                 const duration = (performance.now() - start) / 1000; 
                 score = Math.round(iterations / (duration || 0.001));
             }

             self.postMessage({
               type: "BENCHMARK_COMPLETE",
               score: score,
             });
             return; 
        }
        
        self.postMessage({ success: true, result });

      } catch (err) {
        self.postMessage({ success: false, error: err.message });
      }
    }
  `,
    ],
    { type: "application/javascript" },
  );

  const objectUrl = URL.createObjectURL(blob);
  return { worker: new Worker(objectUrl), objectUrl };
};

// --- MANAGER ---
const applyConfig = () => {
  const targetThreadCount = Math.max(
    1,
    Math.floor(LOGICAL_CORES * throttleLimit),
  );

  // ADD WORKERS
  if (targetThreadCount > threadPool.size) {
    for (let i = threadPool.size; i < targetThreadCount; i++) {
      const wId = nextWorkerId++;
      const { worker, objectUrl } = createSubWorker(wId);

      // PERMANENT LISTENER (Fixes lost benchmark results)
      worker.onmessage = (ev) => {
        const msg = ev.data;

        if (msg.type === "BENCHMARK_COMPLETE") {
          self.postMessage(msg); // Forward to main
        } else if (msg.success || msg.error) {
          // Free up the thread
          const t = threadPool.get(wId);
          if (t) t.busy = false;

          self.postMessage({
            type: msg.success ? "JOB_COMPLETE" : "JOB_ERROR",
            // Note: sub-worker doesn't know chunkId, we'd need to map it if we strictly needed it here,
            // but the current architecture relies on message ordering or we can patch it.
            // For simplicity, we assume the main thread tracks which worker has which chunk
            // BUT actually 'self.onmessage' below has closure over 'chunk.id'.
            // To fix the closure issue properly, we should pass chunkId into the subworker.
            // For now, we rely on the closure in 'self.onmessage' below attaching a specific handler
            // which overrides this one TEMPORARILY.
          });
        }
      };

      threadPool.set(wId, { worker, objectUrl, busy: false });
    }
  }
  // REMOVE WORKERS
  else if (targetThreadCount < threadPool.size) {
    const toRemove = threadPool.size - targetThreadCount;
    let removed = 0;
    for (const [id, thread] of threadPool.entries()) {
      if (!thread.busy && removed < toRemove) {
        thread.worker.terminate();
        URL.revokeObjectURL(thread.objectUrl);
        threadPool.delete(id);
        removed++;
      }
    }
  }
};

applyConfig();

self.onmessage = async (e) => {
  const { type, chunk, throttleLevel } = e.data;

  // 1. CONFIG
  if (type === "UPDATE_CONFIG") {
    if (throttleLevel !== undefined) throttleLimit = throttleLevel;
    applyConfig();
    return;
  }

  // 2. BENCHMARK
  if (type === "BENCHMARK") {
    // Just pick the first available worker
    // Fix: Remove unused 'thread' variable from destructuring
    for (const [id] of threadPool.entries()) {
      const thread = threadPool.get(id);
      if (thread) {
        thread.worker.postMessage({ type: "BENCHMARK" });
        break; // Only run on one thread
      }
    }
    return;
  }

  // 3. JOB PROCESSING
  if (type === "JOB_CHUNK") {
    let selectedId = -1;
    for (const [id, thread] of threadPool.entries()) {
      if (!thread.busy) {
        selectedId = id;
        break;
      }
    }

    if (selectedId === -1) return; // Drop if busy

    const thread = threadPool.get(selectedId)!;
    thread.busy = true;

    // Attach Specific Job Handler (Overrides generic one for this task)
    thread.worker.onmessage = (ev) => {
      thread.busy = false;
      // Restore generic handler? Ideally yes, but 'applyConfig' sets it.
      // We just emit the result.
      self.postMessage({
        type: ev.data.success ? "JOB_COMPLETE" : "JOB_ERROR",
        chunkId: chunk.id,
        result: ev.data.result,
        error: ev.data.error,
      });
    };

    thread.worker.postMessage({ type: chunk.type, data: chunk.data });
  }
};

export {};
</file>

<file path="client/src/hooks/useComputeSwarm.ts">
import { useEffect, useRef, useState } from "react";
import { io, Socket } from "socket.io-client";
import {
  type SwarmSnapshot,
  SwarmRunState,
  DeviceState,
  type JobChunk,
  type WorkerResult,
} from "../../../shared/types";
import OstrichWorker from "../utils/worker?worker";
import { usePersistentIdentity } from "./usePersistentIdentity";

export const useComputeSwarm = (onLog?: (msg: string) => void) => {
  const [snapshot, setSnapshot] = useState<SwarmSnapshot | null>(null);
  const [completedCount, setCompletedCount] = useState(0); // <--- Local State
  const [joinCode, setJoinCode] = useState("LOADING...");

  // Refs
  const completedCountRef = useRef(0);
  const onLogRef = useRef(onLog);
  const socketRef = useRef<Socket | null>(null);
  const workerRef = useRef<Worker | null>(null);

  const identity = usePersistentIdentity();

  useEffect(() => {
    onLogRef.current = onLog;
  }, [onLog]);

  // --- 1. Master Setup ---
  useEffect(() => {
    const worker = new OstrichWorker();
    workerRef.current = worker;

    worker.onmessage = (e) => {
      const { type, chunkId, result, score, error } = e.data;

      if (type === "BENCHMARK_COMPLETE") {
        onLogRef.current?.(`[CPU] Benchmark Result: ${score} OPS`);
        socketRef.current?.emit("benchmark:result", { score });
      } else if (type === "JOB_COMPLETE") {
        completedCountRef.current += 1;
        socketRef.current?.emit("job:complete", {
          chunkId,
          result,
          workerId: identity.id,
        } as WorkerResult);
        socketRef.current?.emit("job:request_batch");
      } else if (type === "JOB_ERROR") {
        socketRef.current?.emit("job:complete", {
          chunkId,
          error,
          workerId: identity.id,
        } as WorkerResult);
      }
    };

    const sUrl = import.meta.env.DEV
      ? `${window.location.protocol}//${window.location.hostname}:3000`
      : window.location.origin;

    const s = io(sUrl, {
      query: { persistentId: identity.id },
      transports: ["websocket"],
      reconnectionAttempts: 10,
    });
    socketRef.current = s;

    s.on("connect", () => {
      onLogRef.current?.(`[NET] Connected as ${identity.name}`);
      s.emit("device:register", {
        name: identity.name,
        type: "DESKTOP",
        capabilities: { cpuCores: navigator.hardwareConcurrency || 4 },
      });
      s.emit("REQUEST_JOIN_CODE");
    });

    s.on("swarm:snapshot", setSnapshot);
    s.on("JOIN_CODE", (d) => setJoinCode(d.code));

    // BENCHMARK TRIGGER
    s.on("cmd:run_benchmark", () => {
      onLogRef.current?.("[SYS] Worker starting benchmark...");
      worker.postMessage({ type: "BENCHMARK" });
    });

    s.on("job:batch", (jobs: JobChunk[]) => {
      jobs.forEach((job) =>
        worker.postMessage({ type: "JOB_CHUNK", chunk: job }),
      );
    });

    return () => {
      s.disconnect();
      worker.terminate();
    };
  }, [identity.id, identity.name]);

  // --- 2. UI Sync Loop ---
  useEffect(() => {
    const uiInterval = setInterval(() => {
      setCompletedCount((prev) => {
        // Sync local ref to state for UI updates
        if (prev !== completedCountRef.current) {
          return completedCountRef.current;
        }
        return prev;
      });
    }, 500);
    return () => clearInterval(uiInterval);
  }, []);

  // --- 3. Auto-Request Loop ---
  useEffect(() => {
    if (!snapshot) return;
    const myDevice = snapshot.devices[identity.id];
    const isSwarmRunning = snapshot.runState === SwarmRunState.RUNNING;
    const amIEnabled =
      myDevice?.state === DeviceState.ONLINE ||
      myDevice?.state === DeviceState.BUSY;

    if (isSwarmRunning && amIEnabled) {
      const interval = setInterval(() => {
        if (socketRef.current?.connected) {
          socketRef.current.emit("job:request_batch");
        }
      }, 1000);
      return () => clearInterval(interval);
    }
  }, [snapshot?.runState, snapshot?.devices, identity.id]);

  return {
    status: snapshot?.runState || SwarmRunState.IDLE,
    stats: snapshot?.stats,
    devices: Object.values(snapshot?.devices || {}),
    myDevice: snapshot?.devices[identity.id],
    joinCode,

    // FIX: Return the LOCAL state, not the snapshot (smoother + solves linter error)
    completedCount: completedCount,

    startSwarm: () =>
      socketRef.current?.emit("cmd:set_run_state", SwarmRunState.RUNNING),
    pauseSwarm: () =>
      socketRef.current?.emit("cmd:set_run_state", SwarmRunState.PAUSED),
    stopSwarm: () =>
      socketRef.current?.emit("cmd:set_run_state", SwarmRunState.STOPPED),
    toggleDevice: (id: string, enabled: boolean) =>
      socketRef.current?.emit("cmd:toggle_device", { id, enabled }),
    updateThrottle: (level: number) =>
      workerRef.current?.postMessage({
        type: "UPDATE_CONFIG",
        throttleLevel: level / 100,
      }),

    runBenchmark: () => {
      onLogRef.current?.("[SYS] Requesting Swarm Benchmark...");
      socketRef.current?.emit("cmd:trigger_benchmark");
    },
  };
};
</file>

<file path="server/src/index.ts">
import { Server } from "socket.io";
import { DeviceManager } from "./managers/DeviceManager";
import { JobScheduler } from "./managers/JobScheduler";
import { type SwarmSnapshot } from "./core/types";

const io = new Server(3000, {
  cors: { origin: "*" },
  transports: ["websocket", "polling"],
});
const deviceManager = new DeviceManager();
const jobScheduler = new JobScheduler();

// GLOBAL STATS
let globalRunState: SwarmSnapshot["runState"] = "STOPPED";
let globalCompletedCount = 0; // Real counter

console.log("ðŸš€ Ostrich Swarm Coordinator Online");

io.on("connection", (socket) => {
  const persistentId = socket.handshake.query.persistentId as string;

  // ... (Keep heartbeat, register, run_state listeners same as before) ...
  socket.on("heartbeat", () => deviceManager.heartbeat(persistentId));
  socket.on("device:register", (data) => {
    console.log(
      `[REG] Device: ${data.name} | Cores: ${data.capabilities.cpuCores}`,
    );
    deviceManager.register(persistentId, data.name, data.capabilities);
    broadcastState();
  });

  socket.on("cmd:set_run_state", (state) => {
    console.log(`[CMD] Swarm State Change: ${globalRunState} -> ${state}`);
    globalRunState = state;
    broadcastState(); // Force immediate update to UI
  });

  socket.on("cmd:toggle_device", ({ id, enabled }) => {
    console.log(`[CMD] Toggle Node ${id}: ${enabled ? "ON" : "OFF"}`);
    deviceManager.toggleDevice(id, enabled);
    broadcastState(); // Force immediate update to UI
  });

  socket.on("job:complete", (_data) => {
    globalCompletedCount++;
    const device = deviceManager
      .getAllDevices()
      .find((d) => d.id === persistentId);
    if (device) device.totalJobsCompleted++;
    // Log every 10th job to avoid spamming terminal but show activity
    if (globalCompletedCount % 10 === 0) {
      console.log(`[JOB] Total Completed: ${globalCompletedCount}`);
    }
  });
  socket.on("cmd:trigger_benchmark", () => io.emit("cmd:run_benchmark"));

  // JOB REQUEST
  socket.on("job:request", () => {
    if (globalRunState !== "RUNNING") return;
    const device = deviceManager
      .getAllDevices()
      .find((d) => d.id === persistentId);
    if (device) {
      const job = jobScheduler.getJobForDevice(device);
      if (job) socket.emit("job:assignment", job);
    }
  });

  // ... disconnect listener ...

  function broadcastState() {
    const resources = deviceManager.getAvailableResources();
    const queue = jobScheduler.getQueueStats();
    const allDevices = deviceManager.getAllDevices();

    // Calculate real velocity by summing the OPS scores of active nodes
    const totalOpsScore = allDevices
      .filter((d) => d.status === "ONLINE" || d.status === "BUSY")
      .reduce((sum, d) => sum + (d.opsScore || 0), 0);

    const snapshot: SwarmSnapshot = {
      runState: globalRunState,
      devices: allDevices.reduce((acc, d) => ({ ...acc, [d.id]: d }), {}),
      stats: {
        totalJobs: globalCompletedCount + queue.pending,
        activeJobs: globalRunState === "RUNNING" ? resources.onlineCount : 0,
        pendingJobs: queue.pending,
        completedJobs: globalCompletedCount,
        globalVelocity: globalRunState === "RUNNING" ? totalOpsScore : 0,
      },
      resources,
    };

    io.emit("swarm:snapshot", snapshot);
  }

  setInterval(broadcastState, 1000);
});
</file>

<file path="client/src/App.tsx">
import { useState } from "react";
import { Zap, Settings, Wifi, WifiOff } from "lucide-react";
import { useSwarmEngine } from "./hooks/useSwarmEngine";
import { useSwarmExecution } from "./hooks/useSwarmExecution";
import { type SwarmResources, type SwarmSnapshot } from "./core/types";

// Features
import { VelocityMonitor } from "./features/dashboard/VelocityMonitor";
import { ActiveSwarm } from "./features/dashboard/ActiveSwarm";
import { ResourceStats } from "./features/dashboard/ResourceStats";
import { JobGauge } from "./features/dashboard/JobGauge";
import { ThrottleControl } from "./features/dashboard/ThrottleControl";
import { LiveTerminal } from "./features/terminal/LiveTerminal";
import { DeviceConnector } from "./features/connection/DeviceConnector";
import { SwarmControls } from "./features/dashboard/SwarmControls";

const EMPTY_SNAPSHOT: SwarmSnapshot = {
  runState: "STOPPED",
  devices: {},
  resources: {
    totalCores: 0,
    totalMemory: 0,
    totalGPUs: 0,
    onlineCount: 0,
  } as SwarmResources,
  stats: {
    totalJobs: 0,
    activeJobs: 0,
    pendingJobs: 0,
    completedJobs: 0,
    globalVelocity: 0,
  },
};

export default function App() {
  const [activeTab, setActiveTab] = useState("Dashboard");
  const [throttle, setThrottle] = useState(40);
  const [isModalOpen, setIsModalOpen] = useState(false);

  // 1. Get Real Data & Logs
  const {
    snapshot: serverSnapshot,
    devices,
    setRunState,
    runLocalBenchmark,
    isConnected,
    toggleDevice,
    totalResources,
    logs,
  } = useSwarmEngine("local-ostrich-01");

  const snapshot = serverSnapshot || EMPTY_SNAPSHOT;
  const isRunning = snapshot.runState === "RUNNING";

  useSwarmExecution(throttle, isRunning);

  return (
    <div className="min-h-screen bg-surface-muted p-4 md:p-8 font-sans antialiased text-text-main selection:bg-brand-orange/20">
      {/* Header */}
      <header className="max-w-7xl mx-auto flex items-center justify-between mb-8 bg-surface-white/90 backdrop-blur-md px-6 py-4 rounded-[28px] border border-white shadow-lg shadow-gray-200/50 sticky top-4 z-50">
        <div className="flex items-center gap-3">
          <div className="w-10 h-10 bg-linear-to-br from-brand-orange to-[#ff9f7c] rounded-xl flex items-center justify-center shadow-lg shadow-brand-orange/30 border-t border-white/20">
            <Zap className="text-white fill-white" size={22} />
          </div>
          <span className="text-xl font-black tracking-tighter text-gray-800">
            Ostrich-Legs
          </span>

          <div
            className={`ml-4 px-3 py-1 rounded-full text-[10px] font-bold flex items-center gap-1.5 border transition-colors ${isConnected ? "bg-green-50 text-green-600 border-green-200" : "bg-red-50 text-red-500 border-red-200"}`}
          >
            {isConnected ? <Wifi size={12} /> : <WifiOff size={12} />}
            {isConnected ? "ONLINE" : "OFFLINE"}
          </div>
        </div>

        <nav className="hidden lg:flex items-center gap-1 bg-gray-100/80 p-1.5 rounded-2xl shadow-inner border border-gray-200/50">
          {["Dashboard", "Monitoring"].map((tab) => (
            <button
              key={tab}
              onClick={() => setActiveTab(tab)}
              className={`px-6 py-2 rounded-xl text-xs font-bold transition-all duration-200 ${activeTab === tab ? "bg-white text-brand-orange shadow-sm border border-gray-100 scale-100" : "text-text-muted hover:text-text-main hover:bg-white/50 scale-95"}`}
            >
              {tab}
            </button>
          ))}
        </nav>

        <div className="flex items-center gap-4">
          <button
            onClick={() => setIsModalOpen(true)}
            className="flex items-center gap-2 group cursor-pointer hover:bg-gray-100 p-2 rounded-xl transition-colors"
          >
            <Settings
              size={20}
              className="text-text-muted group-hover:rotate-90 transition-transform"
            />
          </button>
        </div>
      </header>

      <main className="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-8 pb-12">
        {activeTab === "Dashboard" ? (
          <>
            <div className="lg:col-span-8 space-y-8 min-w-0 flex flex-col">
              <VelocityMonitor
                velocity={snapshot.stats.globalVelocity}
                throttle={throttle}
              />
              <ResourceStats
                stats={snapshot.stats}
                onlineCount={devices.length}
              />
              <div className="flex-1 min-h-75">
                <ActiveSwarm
                  devices={devices}
                  onBenchmark={runLocalBenchmark}
                  onToggle={toggleDevice}
                />
              </div>
            </div>

            <div className="lg:col-span-4 space-y-8 min-w-0">
              {/* 2. Real Job Counts */}
              <JobGauge
                total={snapshot.stats.totalJobs}
                completed={snapshot.stats.completedJobs}
              />

              <SwarmControls
                status={snapshot.runState}
                onToggle={() => setRunState(isRunning ? "PAUSED" : "RUNNING")}
                onStop={() => setRunState("STOPPED")}
              />

              {/* 3. Real Resources */}
              <ThrottleControl
                value={throttle}
                onChange={setThrottle}
                totalGPUs={totalResources.totalGPUs}
                totalCores={totalResources.totalCores}
                totalMemory={totalResources.totalMemory}
              />
            </div>
          </>
        ) : (
          <div className="lg:col-span-12 h-[80vh]">
            {/* 4. Real Logs */}
            <LiveTerminal logs={logs} />
          </div>
        )}
      </main>

      <DeviceConnector
        isOpen={isModalOpen}
        joinCode="OS-99"
        onClose={() => setIsModalOpen(false)}
      />
    </div>
  );
}
</file>

</files>
