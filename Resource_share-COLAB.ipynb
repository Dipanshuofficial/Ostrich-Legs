{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh_ss-Sq2pN9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CmKm_o41_8T",
        "outputId": "cc41c109-c90e-4631-a457-0c804a1f8be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/82.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/59.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install python-socketio --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ostrich Legs Worker Node (v4.0 - Adaptive Benchmark & Polling)\n",
        "# @markdown Run this cell to join the compute swarm!\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import uuid\n",
        "import threading\n",
        "import platform\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. INSTALL DEPENDENCIES ---\n",
        "try:\n",
        "    import socketio\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-socketio[client]\", \"requests\"])\n",
        "    import socketio\n"
      ],
      "metadata": {
        "id": "WhzaxOm_QbZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try importing Torch for GPU support\n",
        "HAS_GPU = False\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        HAS_GPU = True\n",
        "        print(f\"ðŸš€ GPU DETECTED: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ GPU not found. Falling back to CPU.\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ PyTorch not installed. Falling back to CPU.\")\n"
      ],
      "metadata": {
        "id": "VTIB47esQgO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. KERNELS ---\n",
        "\n",
        "def run_stress_test(iterations):\n",
        "    \"\"\"CPU Bound Stress Test\"\"\"\n",
        "    start = time.time()\n",
        "    count = int(iterations or 100000)\n",
        "    # CPU heavy vector math\n",
        "    x = np.random.rand(int(count/100))\n",
        "    np.sin(x) * np.sqrt(x)\n",
        "    return float(time.time() - start)\n",
        "\n",
        "def run_matrix_mul(data):\n",
        "    \"\"\"Hybrid GPU/CPU Matrix Multiplication\"\"\"\n",
        "    start = time.time()\n",
        "\n",
        "    # Extract dimensions (default 300 for normal jobs)\n",
        "    size = int(data.get('size', 300))\n",
        "\n",
        "    if HAS_GPU:\n",
        "        # GPU PATH\n",
        "        a = torch.rand(size, size, device='cuda')\n",
        "        b = torch.rand(size, size, device='cuda')\n",
        "        torch.matmul(a, b)\n",
        "        torch.cuda.synchronize()\n",
        "    else:\n",
        "        # CPU PATH\n",
        "        a = np.random.rand(size, size)\n",
        "        b = np.random.rand(size, size)\n",
        "        np.dot(a, b)\n",
        "\n",
        "    return float(time.time() - start)\n",
        "\n",
        "def process_job(job):\n",
        "    global last_work_time\n",
        "    if not sio.connected: return False\n",
        "\n",
        "    job_id = job['id']\n",
        "    job_type = job['type']\n",
        "    job_data = job['data']\n",
        "\n",
        "    try:\n",
        "        duration = 0\n",
        "        if job_type == 'MATH_STRESS':\n",
        "            duration = run_stress_test(job_data.get('iterations', 50000))\n",
        "        elif job_type == 'MAT_MUL':\n",
        "            duration = run_matrix_mul(job_data)\n",
        "\n",
        "        last_work_time = time.time()\n",
        "\n",
        "        if sio.connected:\n",
        "            sio.emit('job:complete', {\n",
        "                'chunkId': job_id,\n",
        "                'result': 'Calculated',\n",
        "                'durationMs': duration * 1000,\n",
        "                'workerId': DEVICE_ID,\n",
        "                'timestamp': time.time() * 1000\n",
        "            })\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"\\nJob Error: {e}\")\n",
        "        if sio.connected:\n",
        "            sio.emit('job:complete', {\n",
        "                'chunkId': job_id,\n",
        "                'error': str(e),\n",
        "                'workerId': DEVICE_ID\n",
        "            })\n",
        "        return False\n",
        "\n",
        "# --- 5. EVENTS ---\n",
        "\n",
        "@sio.event\n",
        "def connect():\n",
        "    print(f\"\\nâœ… Connected! ID: {DEVICE_ID}\")\n",
        "\n",
        "    # Detect System Info\n",
        "    import multiprocessing\n",
        "    cores = multiprocessing.cpu_count()\n",
        "    mem = 12\n",
        "\n",
        "    sio.emit('device:register', {\n",
        "        'name': DEVICE_NAME,\n",
        "        'type': 'COLAB',\n",
        "        'capabilities': {\n",
        "            'cpuCores': cores,\n",
        "            'memoryGB': mem,\n",
        "            'gpuAvailable': HAS_GPU,\n",
        "            # If GPU, we can handle huge concurrency because CUDA is parallel\n",
        "            'maxConcurrency': cores * 4 if HAS_GPU else cores,\n",
        "            'supportedJobs': ['MATH_STRESS', 'MAT_MUL']\n",
        "        }\n",
        "    })\n",
        "\n",
        "@sio.on('job:batch')\n",
        "def on_batch(jobs):\n",
        "    global is_working\n",
        "    is_working = True\n",
        "    print(f\"\\rðŸ“¦ Batch: {len(jobs)} | GPU: {'ON' if HAS_GPU else 'OFF'}\", end=\"\")\n",
        "\n",
        "    for job in jobs:\n",
        "        if not sio.connected: break\n",
        "        process_job(job)\n",
        "\n",
        "    is_working = False\n",
        "\n",
        "    # Pull next batch\n",
        "    if sio.connected:\n",
        "        sio.emit('job:request_batch')\n",
        "\n",
        "@sio.on('cmd:run_benchmark')\n",
        "def on_benchmark():\n",
        "    print(\"\\nðŸš€ Starting Benchmark...\", end=\"\")\n",
        "    try:\n",
        "        start = time.time()\n",
        "        score = 0\n",
        "\n",
        "        if HAS_GPU:\n",
        "            # CASE A: GPU (Heavy Matrix Mul)\n",
        "            size = 1000\n",
        "            a = torch.rand(size, size, device='cuda')\n",
        "            b = torch.rand(size, size, device='cuda')\n",
        "            torch.matmul(a, b)\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            duration = time.time() - start\n",
        "            # Formula: 2 Billion Ops / Seconds\n",
        "            score = int(2000000000 / (duration + 0.00001))\n",
        "            print(f\" [GPU MODE] Score: {score:,}\")\n",
        "\n",
        "        else:\n",
        "            # CASE B: CPU (Simple Loop)\n",
        "            # 5 Million Iterations\n",
        "            count = 5000000\n",
        "            x = np.random.rand(int(count/100))\n",
        "            np.sin(x) * np.sqrt(x)\n",
        "\n",
        "            duration = time.time() - start\n",
        "            # Formula: Iterations / Seconds\n",
        "            score = int(count / (duration + 0.00001))\n",
        "            print(f\" [CPU MODE] Score: {score:,}\")\n",
        "\n",
        "        sio.emit('benchmark:result', {'score': score})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Benchmark Failed: {e}\")\n",
        "\n",
        "@sio.event\n",
        "def disconnect():\n",
        "    print(\"\\nâŒ Disconnected from server.\")\n",
        "\n",
        "# --- 6. BACKGROUND POLLER ---\n",
        "def poller_loop():\n",
        "    while True:\n",
        "        try:\n",
        "            # If idle for >1s, ask for work\n",
        "            if sio.connected and not is_working:\n",
        "                if time.time() - last_work_time > 1.0:\n",
        "                    sio.emit('job:request_batch')\n",
        "            time.sleep(1.0)\n",
        "        except:\n",
        "            pass\n"
      ],
      "metadata": {
        "id": "ou5a0ug1Qsqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. IDENTITY ---\n",
        "id_file = \"device_identity.txt\"\n",
        "if os.path.exists(id_file):\n",
        "    with open(id_file, \"r\") as f:\n",
        "        DEVICE_ID = f.read().strip()\n",
        "else:\n",
        "    DEVICE_ID = f\"colab-{str(uuid.uuid4())[:8]}\"\n",
        "    with open(id_file, \"w\") as f:\n",
        "        f.write(DEVICE_ID)\n",
        "\n",
        "sio = socketio.Client(reconnection=True, reconnection_delay=5)\n",
        "is_working = False\n",
        "last_work_time = time.time()\n"
      ],
      "metadata": {
        "id": "3x1KtBgcQvKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. CONFIGURATION ---\n",
        "SERVER_URL = \"https://public-pride-bought-sys.trycloudflare.com/\" # @param {type:\"string\"}\n",
        "DEVICE_NAME = \"Colab-Node-01\" # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "# --- 7. MAIN START ---\n",
        "def main():\n",
        "    print(f\"ðŸš€ Initializing Worker {DEVICE_ID}...\")\n",
        "\n",
        "    # Start Poller\n",
        "    t = threading.Thread(target=poller_loop, daemon=True)\n",
        "    t.start()\n",
        "\n",
        "    # Auth URL\n",
        "    auth_url = f\"{SERVER_URL}?persistentId={DEVICE_ID}\"\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            if not sio.connected:\n",
        "                print(f\"Connecting to {SERVER_URL}...\")\n",
        "                sio.connect(auth_url, transports=['websocket', 'polling'])\n",
        "                sio.wait()\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nStopping...\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Connection Error: {e}\")\n",
        "            time.sleep(5)\n"
      ],
      "metadata": {
        "id": "5zJYP80nQ3Z8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "dfTz0baT1GI1",
        "collapsed": true,
        "outputId": "eaf27aba-a478-4785-e2b5-82adfa6fcdbd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'main' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-217905245.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Fi0UHRcQ_ws"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}